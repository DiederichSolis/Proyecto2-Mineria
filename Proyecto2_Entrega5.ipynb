{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "53128aae",
      "metadata": {
        "id": "53128aae"
      },
      "source": [
        "# Punto 1: Creación de Variables Dicotómicas\n",
        "\n",
        "**Enunciado:**  \n",
        "Se debe crear una variable dicotómica para cada una de las categorías de la variable respuesta categórica que se definió en hojas anteriores. Es decir, se deben generar tres nuevas variables (con valores 0 y 1) que indiquen si una vivienda es:\n",
        "- **Cara o no:** Una variable que tome el valor 1 si la vivienda se clasifica como \"cara\" y 0 en caso contrario.\n",
        "- **Media o no:** Una variable que indique si la vivienda se encuentra en la categoría \"media\" (por ejemplo, en el tercil intermedio) y 0 si no lo es.\n",
        "- **Económica o no:** Una variable que tome el valor 1 si la vivienda es \"económica\" (por ejemplo, en el tercil inferior) y 0 en caso contrario.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b6e6a38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b6e6a38",
        "outputId": "af5fc1ef-71e9-4c88-9891-b1c49be58b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Dummies creadas y archivo guardado.\n",
            "   SalePrice cat_price  is_barata  is_media  is_cara\n",
            "0     208500      cara          0         0        1\n",
            "1     181500     media          0         1        0\n",
            "2     223500      cara          0         0        1\n",
            "3     140000     media          0         1        0\n",
            "4     250000      cara          0         0        1\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np, joblib\n",
        "\n",
        "# cargar datos\n",
        "df = pd.read_csv('train.csv')              # <-- ruta al archivo base\n",
        "\n",
        "# calcular terciles y categorías\n",
        "q1, q2 = df['SalePrice'].quantile([.33, .66])\n",
        "\n",
        "def categoria(p):\n",
        "    if p <= q1:       return 'barata'\n",
        "    elif p <= q2:     return 'media'\n",
        "    else:             return 'cara'\n",
        "\n",
        "df['cat_price'] = df['SalePrice'].apply(categoria)\n",
        "df['is_barata'] = (df['cat_price'] == 'barata').astype(int)\n",
        "df['is_media']  = (df['cat_price'] == 'media' ).astype(int)\n",
        "df['is_cara']   = (df['cat_price'] == 'cara'  ).astype(int)\n",
        "\n",
        "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# guardar dataset y puntos de corte\n",
        "df.to_csv('data/train_cat.csv', index=False)\n",
        "joblib.dump({'q1': q1, 'q2': q2}, 'data/cut_points.joblib')\n",
        "\n",
        "print(\"✔ Dummies creadas y archivo guardado.\")\n",
        "print(df[['SalePrice','cat_price','is_barata','is_media','is_cara']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ba9907",
      "metadata": {
        "id": "13ba9907"
      },
      "source": [
        "El criterio de clasificación puede basarse en los terciles o percentiles del valor de la vivienda (por ejemplo, la variable `SalePrice`).\n",
        "\n",
        "**Interpretación de Resultados:**  \n",
        "- **Variable `is_cara`:** Indica que una vivienda se considera cara cuando su precio se encuentra en el tercil superior. Un valor de 1 implica que la propiedad tiene un precio alto, mientras que 0 indica lo contrario.\n",
        "- **Variable `is_media`:** Indica que una vivienda está en una categoría de precio intermedia (típicamente, el tercil medio). Un 1 en esta variable significa que la propiedad no es ni cara ni económica, sino que se ubica en un rango intermedio.\n",
        "- **Variable `is_economica` (o `is_barata`):** Señala que una vivienda es económica cuando su precio está en el tercil inferior. Un valor de 1 significa que la propiedad se clasifica como de bajo costo, lo que puede estar vinculado a características específicas o a ubicaciones menos privilegiadas.\n",
        "\n",
        "El uso de estas variables dicotómicas facilita la aplicación de modelos de clasificación en entregas posteriores, permitiendo analizar y comparar el desempeño de distintos algoritmos (por ejemplo, Regresión Logística, Árboles de Decisión, Random Forest, etc.) con base en categorías bien definidas del precio de la vivienda. Además, estas variables ayudan a identificar qué características influyen en el precio y a plantear estrategias específicas en el sector inmobiliario."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "756cab2b",
      "metadata": {
        "id": "756cab2b"
      },
      "source": [
        "# Punto 2: Uso de los mismos conjuntos de entrenamiento y prueba\n",
        "\n",
        "**Enunciado:**  \n",
        "Se deben utilizar los mismos conjuntos de entrenamiento y prueba (train/test) que se definieron en las hojas anteriores. Esto permite asegurar la reproducibilidad de los experimentos y la coherencia en las comparaciones de rendimiento entre distintos modelos y pasos del proyecto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e63e5177",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e63e5177",
        "outputId": "24783649-799e-4225-f5ef-25e1cef86490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits guardados – reproducibles.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd, joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "SEED = 221087\n",
        "df = pd.read_csv('data/train_cat.csv')\n",
        "\n",
        "y = df['is_cara']                                   # objetivo dicotómico\n",
        "X = df.drop(columns=['SalePrice','cat_price',\n",
        "                     'is_barata','is_media','is_cara'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
        "\n",
        "joblib.dump((X_train,X_test,y_train,y_test),'data/splits.joblib')\n",
        "print(\"Splits guardados – reproducibles.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa72192",
      "metadata": {
        "id": "5aa72192"
      },
      "source": [
        "**Interpretación de Resultados:**  \n",
        "- **Consistencia de la Evaluación:** Al emplear exactamente los mismos datos de entrenamiento y de prueba en cada modelo, se logra comparar de forma justa (fair comparison) los distintos enfoques de clasificación.  \n",
        "- **Reproducibilidad:** Fijar una semilla (por ejemplo, `SEED = 221087`) y utilizar la misma partición asegura que, cada vez que se ejecuta el script, se obtenga el mismo `X_train`, `X_test`, `y_train`, `y_test`. Esto facilita depurar errores, compartir resultados y garantizar que el comportamiento de los modelos no varíe por cambios accidentales en los datos.  \n",
        "- **Enfoque Científico:** Mantener los mismos conjuntos de entrenamiento y prueba es clave para la validez de los experimentos de minería de datos y aprendizaje automático, ya que se aísla la evaluación de los modelos de factores externos y se reduce el riesgo de sobreajuste o de sesgos en la división de los datos.  \n",
        "\n",
        "En esta etapa, simplemente confirmamos y documentamos el uso de la misma partición que se estableció en las hojas anteriores para todos los modelos subsecuentes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3212183a",
      "metadata": {
        "id": "3212183a"
      },
      "source": [
        "# Punto 3: Modelo de Regresión Logística para determinar si una vivienda es cara o no\n",
        "\n",
        "**Enunciado:**  \n",
        "Se debe elaborar un modelo de Regresión Logística para predecir si una vivienda es \"cara\" (es decir, si `is_cara == 1`). El entrenamiento debe realizarse únicamente con el conjunto de entrenamiento establecido y debe incluir:\n",
        "1. Un pipeline de preprocesamiento (por ejemplo, imputación de datos faltantes y/o escalado).\n",
        "2. Una etapa de validación cruzada para estimar la capacidad de generalización del modelo.\n",
        "3. La fijación de la semilla y la partición de los datos para garantizar que el experimento sea reproducible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b365dd15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b365dd15",
        "outputId": "eb6722f5-11bd-4fe5-f98d-2a5f82de9d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud CV por fold: [0.923 0.902 0.932 0.931 0.91 ] | Media: 0.920\n",
            "✔ Modelo guardado en models/logit_cara.joblib\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "SEED = 221087\n",
        "\n",
        "X_train, X_test, y_train, y_test = joblib.load('data/splits.joblib')\n",
        "\n",
        "# columnas numéricas y categóricas\n",
        "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = X_train.select_dtypes(exclude=['int64', 'float64']).columns\n",
        "\n",
        "# Pipelines de pre‑proceso\n",
        "num_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler',  StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot',  OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "prepro = ColumnTransformer([\n",
        "    ('num', num_pipe, num_cols),\n",
        "    ('cat', cat_pipe, cat_cols)\n",
        "])\n",
        "\n",
        "# Modelo de Regresión Logística\n",
        "logit = LogisticRegression(max_iter=1000, random_state=SEED)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('prep', prepro),\n",
        "    ('clf',  logit)\n",
        "])\n",
        "\n",
        "# Validación cruzada estratificada (5‑fold)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(f\"Exactitud CV por fold: {np.round(scores, 3)} | Media: {scores.mean():.3f}\")\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "Path('models').mkdir(parents=True, exist_ok=True)\n",
        "joblib.dump(pipe, 'models/logit_cara.joblib')\n",
        "print(\"✔ Modelo guardado en models/logit_cara.joblib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853177e7",
      "metadata": {
        "id": "853177e7"
      },
      "source": [
        "Una vez entrenado el modelo, se debe explicar brevemente los resultados a los que se llega (por ejemplo, el valor de la métrica de validación cruzada). El objetivo es que, cada vez que se ejecute el código, se utilicen los mismos conjuntos de entrenamiento y prueba, y se obtengan resultados consistentes.\n",
        "\n",
        "**Interpretación de Resultados:**  \n",
        "- **Entrenamiento y Pipeline:** El modelo de Regresión Logística aprende, a partir de las variables predictoras (features), la probabilidad de que una vivienda sea cara (clase positiva). Mediante la combinación de imputación y escalado, se normalizan los datos para estabilizar los coeficientes y facilitar la convergencia del algoritmo.\n",
        "- **Validación Cruzada:** Al usar una técnica como k‑fold (por ejemplo, con 5 pliegues), se obtiene una mejor aproximación de la capacidad de generalización del modelo, reduciendo la dependencia de una sola partición. Se presentan métricas como el accuracy promedio y la desviación estándar entre pliegues.\n",
        "- **Reproducibilidad:** Fijar la semilla y emplear los mismos splits de entrenamiento y prueba permite que cualquier persona que ejecute el código obtenga los mismos resultados, lo cual es esencial para la robustez de la investigación.\n",
        "- **Rendimiento y Métricas:** Si, por ejemplo, la validación cruzada arroja una exactitud promedio de 0.85 con una desviación de 0.02, esto significa que el modelo acierta en un 85 % de los casos, en promedio, al determinar si una vivienda es cara o no. Esta métrica puede complementarse con ROC AUC, precisión (precision), exhaustividad (recall) y otras para profundizar en la evaluación.\n",
        "- **Almacenamiento del Modelo:** Guardar el modelo (por ejemplo, en un archivo `.joblib`) tras entrenarlo facilita su uso posterior para la etapa de predicción o para su integración con otros sistemas, sin tener que reentrenarlo cada vez.\n",
        "\n",
        "Con esto se logra un modelo capaz de distinguir entre viviendas caras y no caras, fundamentado en un proceso reproducible y validado, lo cual proporciona la base para escalas mayores o proyectos posteriores en el área de minería de datos y aprendizaje automático."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b05cab5e",
      "metadata": {
        "id": "b05cab5e"
      },
      "source": [
        "# Punto 4: Análisis del Modelo y Detección de Multicolinealidad\n",
        "\n",
        "**Enunciado:**  \n",
        "1. Analizar el modelo entrenado previamente para determinar:\n",
        "   - Si existe multicolinealidad en las variables.\n",
        "   - Cuáles variables aportan significativamente al modelo (con base en su p‑value, VIF, etc.).\n",
        "   - La correlación existente entre las variables usadas en el modelo.\n",
        "2. Especificar si el modelo se adapta bien a los datos, basándose en medidas como el R‑cuadrado pseudo, log‑likelihood o en el comportamiento de los coeficientes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "141229a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "141229a6",
        "outputId": "94815cd2-e0e2-41d8-dfdd-316524ad568b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rango inicial de la matriz (incl. constante): 239 de 243 columnas\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping column 'BsmtFinSF1' (VIF: inf) due to singularity.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping column '1stFlrSF' (VIF: inf) due to singularity.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping column 'Exterior1st_CBlock' (VIF: inf) due to singularity.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping column 'BsmtCond_Po' (VIF: inf) due to singularity.\n",
            "Rango final de la matriz: 239 de 239 columnas\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-X))\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.sum(np.log(self.cdf(q * linpred)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ajuste exitoso usando método 'lbfgs'.\n",
            "✔ Resultados guardados en 'tables/logit_coeffs_pvalues.csv'\n",
            "✔ VIF guardado en 'tables/vif_logit.csv'\n",
            "✔ Matriz de correlación guardada en 'tables/corr_numeric.csv'\n",
            "\n",
            "Top‑10 variables más significativas (ordenadas por p‑value ascendente):\n",
            "              Coef.  P>|z|\n",
            "const           0.0    1.0\n",
            "Id              0.0    1.0\n",
            "MSSubClass      0.0    1.0\n",
            "LotFrontage     0.0    1.0\n",
            "LotArea         0.0    1.0\n",
            "OverallQual     0.0    1.0\n",
            "OverallCond     0.0    1.0\n",
            "YearBuilt       0.0    1.0\n",
            "YearRemodAdd    0.0    1.0\n",
            "MasVnrArea      0.0    1.0\n",
            "\n",
            "Top‑10 VIF más altos:\n",
            "                 feature           VIF\n",
            "0                  const  3.362789e+06\n",
            "215        GarageCond_TA  2.136384e+02\n",
            "211        GarageQual_TA  2.043732e+02\n",
            "104      RoofStyle_Gable  1.367854e+02\n",
            "106        RoofStyle_Hip  1.261288e+02\n",
            "125  Exterior1st_VinylSd  1.173327e+02\n",
            "140  Exterior2nd_VinylSd  1.043268e+02\n",
            "121  Exterior1st_MetalSd  7.946753e+01\n",
            "38           MSZoning_RL  7.720506e+01\n",
            "109     RoofMatl_CompShg  7.604156e+01\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import joblib, pandas as pd, numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Función auxiliar para eliminar columnas que causen colinealidad\n",
        "def get_full_rank_columns(X):\n",
        "    cols = list(X.columns)\n",
        "    while np.linalg.matrix_rank(X[cols].values) < len(cols):\n",
        "        # Calcular VIF para cada columna\n",
        "        vif_series = pd.Series(\n",
        "            [variance_inflation_factor(X[cols].values, i) for i in range(len(cols))],\n",
        "            index=cols\n",
        "        )\n",
        "        # Se elimina la columna con el VIF más alto\n",
        "        drop_col = vif_series.idxmax()\n",
        "        print(f\"Dropping column '{drop_col}' (VIF: {vif_series[drop_col]:.2f}) due to singularity.\")\n",
        "        cols.remove(drop_col)\n",
        "    return cols\n",
        "\n",
        "X_train, X_test, y_train, y_test = joblib.load('data/splits.joblib')\n",
        "X_dum = pd.get_dummies(X_train, drop_first=True)\n",
        "X_dum = X_dum.loc[:, (X_dum != X_dum.iloc[0]).any()]  # eliminar columnas sin variación\n",
        "\n",
        "# Imputar valores faltantes\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "X_dum_imp = pd.DataFrame(\n",
        "    imp.fit_transform(X_dum),\n",
        "    columns=X_dum.columns,\n",
        "    index=X_dum.index\n",
        ").astype(float)\n",
        "\n",
        "X_const = sm.add_constant(X_dum_imp, prepend=True)\n",
        "initial_rank = np.linalg.matrix_rank(X_const.values)\n",
        "print(f\"Rango inicial de la matriz (incl. constante): {initial_rank} de {X_const.shape[1]} columnas\")\n",
        "\n",
        "# Eliminar columnas colineales hasta lograr rango completo\n",
        "full_rank_cols = get_full_rank_columns(X_const)\n",
        "X_const_full = X_const[full_rank_cols]\n",
        "final_rank = np.linalg.matrix_rank(X_const_full.values)\n",
        "print(f\"Rango final de la matriz: {final_rank} de {X_const_full.shape[1]} columnas\")\n",
        "\n",
        "# Ajustar el modelo Logit\n",
        "try:\n",
        "    logit_sm = sm.Logit(y_train.astype(float), X_const_full).fit(disp=False, method='lbfgs')\n",
        "    print(\"Ajuste exitoso usando método 'lbfgs'.\")\n",
        "except Exception as e:\n",
        "    print(\"Error en ajuste con 'lbfgs':\", e)\n",
        "    print(\"Usando ajuste regularizado...\")\n",
        "    logit_sm = sm.Logit(y_train.astype(float), X_const_full).fit_regularized(maxiter=1000, disp=False)\n",
        "    print(\"Ajuste regularizado completado.\")\n",
        "\n",
        "# Guardar el resumen (coeficientes y, si disponible, p‑values) en CSV\n",
        "Path('tables').mkdir(parents=True, exist_ok=True)\n",
        "try:\n",
        "    summary_table = logit_sm.summary2().tables[1]\n",
        "except Exception:\n",
        "    # Si se usó regularización, puede que summary2 no incluya p‑values.\n",
        "    summary_table = pd.DataFrame({'coef': logit_sm.params})\n",
        "summary_table.to_csv('tables/logit_coeffs_pvalues.csv')\n",
        "print(\"✔ Resultados guardados en 'tables/logit_coeffs_pvalues.csv'\")\n",
        "\n",
        "# Calcular VIF para las variables del modelo\n",
        "vif_df = pd.DataFrame({\n",
        "    'feature': X_const_full.columns,\n",
        "    'VIF': [variance_inflation_factor(X_const_full.values, i)\n",
        "            for i in range(X_const_full.shape[1])]\n",
        "})\n",
        "vif_df.to_csv('tables/vif_logit.csv', index=False)\n",
        "print(\"✔ VIF guardado en 'tables/vif_logit.csv'\")\n",
        "\n",
        "num_cols = X_train.select_dtypes(include=['int64','float64']).columns\n",
        "corr = X_train[num_cols].corr()\n",
        "corr.to_csv('tables/corr_numeric.csv')\n",
        "print(\"✔ Matriz de correlación guardada en 'tables/corr_numeric.csv'\")\n",
        "\n",
        "# Mostrar resultados clave en consola\n",
        "print(\"\\nTop‑10 variables más significativas (ordenadas por p‑value ascendente):\")\n",
        "try:\n",
        "    print(summary_table.sort_values('P>|z|').head(10)[['Coef.', 'P>|z|']])\n",
        "except Exception:\n",
        "    print(summary_table.sort_values('coef').head(10))\n",
        "\n",
        "print(\"\\nTop‑10 VIF más altos:\")\n",
        "print(vif_df.sort_values('VIF', ascending=False).head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e451d1",
      "metadata": {
        "id": "f1e451d1"
      },
      "source": [
        "**Interpretación de Resultados:**  \n",
        "- **Multicolinealidad:**  \n",
        "  - Mediante la **varianza inflation factor (VIF)** o la inspección de correlaciones muy altas (por ejemplo, |ρ| > 0.8) se puede evidenciar si dos o más variables se solapan en la información que aportan al modelo. Un valor de VIF > 10 suele considerarse indicio de multicolinealidad seria.  \n",
        "  - La multicolinealidad extrema puede causar inestabilidad en los coeficientes de la Regresión Logística, dificultando la interpretación y generando problemas de sobreajuste o de singularidad de la matriz.\n",
        "- **Variables Significativas:**  \n",
        "  - El **p‑value** asociado a cada coeficiente (en un ajuste sin regularización severa) indica qué tan relevante es la variable para predecir la categoría de la vivienda (cara o no, en este caso). Usualmente se toman como significativas las variables con p‑value < 0.05.  \n",
        "  - Si el ajuste se hace con regularización, la interpretación tradicional de p‑values puede no estar disponible; en ese caso, se valoran los coeficientes que el modelo conserva (no penalizados a cero) como los más influyentes.\n",
        "- **Correlación entre las Variables:**  \n",
        "  - Examinar la **matriz de correlación** de las variables numéricas originales (o tras ciertas transformaciones) revela relaciones lineales fuertes. Por ejemplo, si `GarageArea` y `GarageCars` están fuertemente correlacionadas, puede sugerir que solo una de ellas es estrictamente necesaria.\n",
        "  - Un análisis de correlación previo a la modelación permite reducir redundancias y mejorar la estabilidad del modelo.\n",
        "- **Adaptación del Modelo a los Datos:**  \n",
        "  - Para la Regresión Logística, suele analizarse el **Pseudo R‑squared (McFadden, Nagelkerke, etc.)** y el **Log‑likelihood** final. Valores más altos (o menos negativos, en el caso del log‑likelihood) sugieren un mejor ajuste.  \n",
        "  - Sin embargo, un Pseudo R‑squared bajo no siempre implica un mal modelo: en clasificación, métricas como la exactitud, ROC AUC o la matriz de confusión pueden ser más relevantes para validar la calidad.\n",
        "  - Si se observan avisos de “Singular matrix” o “divide by zero encountered”, es síntoma de multicolinealidad extrema o de separación casi perfecta en los datos, lo cual puede requerir eliminación de variables redundantes o uso de regularización.\n",
        "\n",
        "**Conclusión General del Análisis:**  \n",
        "- En este punto, se profundiza en la naturaleza del modelo: las variables más explicativas, la presencia de correlaciones redundantes y la robustez del ajuste.  \n",
        "- Cualquier hallazgo de multicolinealidad severa o de variables con p‑values altos (p > 0.05) se documenta y se decide (o no) su exclusión en modelos posteriores.  \n",
        "- Si el modelo presenta un comportamiento estable (sin grandes discrepancias, sin singularidades) y las métricas sugieren una buena discriminación entre viviendas caras y no caras, se concluye que el modelo se adapta adecuadamente a los datos. De lo contrario, se plantea un refinamiento adicional en pasos posteriores (por ejemplo, ajustando hiperparámetros, eliminando variables o aplicando técnicas de regularización)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e04dc7c",
      "metadata": {
        "id": "4e04dc7c"
      },
      "source": [
        "# Punto 5: Evaluación del Modelo en el Conjunto de Prueba\n",
        "\n",
        "**Enunciado:**  \n",
        "Se debe utilizar el modelo entrenado (por ejemplo, la Regresión Logística) con el conjunto de prueba (test set) y determinar la eficiencia del algoritmo para clasificar si una vivienda es cara o no. Para ello, se calculan e interpretan métricas de evaluación tales como:\n",
        "\n",
        "- **Exactitud (accuracy)**  \n",
        "- **ROC AUC**  \n",
        "- **Reporte de Clasificación** (precisión, recall, F1‑score, soporte)  \n",
        "- **Matriz de Confusión**  \n",
        "\n",
        "Estas métricas son fundamentales para cuantificar el desempeño real del modelo en datos que no fueron usados durante el entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edaaa0a9",
      "metadata": {
        "id": "edaaa0a9"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = joblib.load('data/splits.joblib')\n",
        "model = joblib.load('models/logit_cara.joblib')\n",
        "\n",
        "# Realizar predicciones sobre el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "if hasattr(model, \"predict_proba\"):\n",
        "    y_proba = model.predict_proba(X_test)[:,1]\n",
        "else:\n",
        "\n",
        "    y_proba = model.decision_function(X_test)\n",
        "\n",
        "# Calcular métricas de evaluación\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc  = roc_auc_score(y_test, y_proba)\n",
        "report   = classification_report(y_test, y_pred)\n",
        "cm       = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Mostrar resultados en consola\n",
        "print(\"=== Evaluación del modelo en el conjunto de prueba ===\")\n",
        "print(f\"Accuracy (Exactitud): {accuracy:.3f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(report)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(cm)\n",
        "\n",
        "pd.DataFrame({'Accuracy': [accuracy], 'ROC_AUC': [roc_auc]}).to_csv(\"tables/test_metrics.csv\", index=False)\n",
        "pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicho 0\", \"Predicho 1\"]).to_csv(\"tables/confusion_matrix.csv\")\n",
        "with open(\"tables/classification_report.txt\", \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"\\n✔ Resultados guardados en la carpeta 'tables'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b93822",
      "metadata": {
        "id": "b2b93822"
      },
      "source": [
        "**Interpretación de Resultados:**  \n",
        "1. **Exactitud (Accuracy):**  \n",
        "   Mide la proporción de instancias correctamente clasificadas (tanto positivas como negativas). Un valor de 0.911, por ejemplo, indica que el 91.1 % de las viviendas fueron clasificadas correctamente como caras o no caras.\n",
        "\n",
        "2. **ROC AUC:**  \n",
        "   Evalúa la capacidad del modelo para separar correctamente las clases a lo largo de diferentes umbrales de clasificación. Un valor cercano a 1.0 sugiere una discriminación casi perfecta. Por ejemplo, un ROC AUC de 0.90 indica que, en el 90 % de los casos, el modelo ordena correctamente un ejemplo positivo por encima de uno negativo.\n",
        "\n",
        "3. **Reporte de Clasificación:**  \n",
        "   - **Precisión (Precision):** Proporción de verdaderos positivos entre todos los elementos predichos como positivos.  \n",
        "   - **Recall (Exhaustividad/Sensibilidad):** Proporción de verdaderos positivos detectados con respecto a todos los positivos reales.  \n",
        "   - **F1-Score:** Media armónica entre la precisión y el recall, útil cuando se busca un balance entre ambos.  \n",
        "   - **Soporte:** Número de muestras reales que corresponden a cada clase.  \n",
        "\n",
        "4. **Matriz de Confusión:**  \n",
        "   - Muestra la distribución de aciertos y errores desglosados por clase (caras vs. no caras).  \n",
        "   - Permite ver en qué clase el modelo está cometiendo más equivocaciones (falsos positivos o falsos negativos).\n",
        "\n",
        "5. **Importancia de una Evaluación Integral:**  \n",
        "   Aunque la exactitud y el ROC AUC son buenas métricas globales, el análisis detallado a través del reporte de clasificación y la matriz de confusión brinda información más específica sobre en qué casos o clases el modelo se desempeña mejor o tiene dificultades.  \n",
        "   Esto es especialmente valioso cuando las clases están desbalanceadas o cuando cierto tipo de error es más costoso que otro.\n",
        "\n",
        "En conclusión, el punto 5 valida la **eficacia del modelo en datos que no se han visto durante el entrenamiento**, asegurando que el rendimiento reportado no esté sobreestimado. Un buen desempeño en el conjunto de prueba indica que el modelo generaliza adecuadamente y puede aplicarse en situaciones reales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4132f430",
      "metadata": {
        "id": "4132f430"
      },
      "source": [
        "# Punto 6: Detección de Sobreajuste y Curvas de Aprendizaje\n",
        "\n",
        "**Enunciado:**  \n",
        "Se debe explicar si existe sobreajuste (overfitting) o no en el modelo, empleando para ello los errores en el conjunto de entrenamiento y en el conjunto de prueba. Adicionalmente, se deben mostrar las curvas de aprendizaje (learning curves) que reflejen cómo evoluciona la métrica de error (o precisión) a medida que aumenta el tamaño de la muestra de entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d4635f",
      "metadata": {
        "id": "77d4635f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.model_selection import learning_curve\n",
        "from pathlib import Path\n",
        "\n",
        "X_train, X_test, y_train, y_test = joblib.load('data/splits.joblib')\n",
        "model = joblib.load('models/logit_cara.joblib')\n",
        "\n",
        "# Calcular la curva de aprendizaje\n",
        "train_sizes, train_scores, valid_scores = learning_curve(\n",
        "    model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring='neg_log_loss',\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    n_jobs=-1  # usar todos los núcleos disponibles\n",
        ")\n",
        "\n",
        "# Dado que se usa \"neg_log_loss\", convertimos a error (multiplicando por -1)\n",
        "train_errors = -np.mean(train_scores, axis=1)\n",
        "valid_errors = -np.mean(valid_scores, axis=1)\n",
        "\n",
        "# Graficar las curvas de aprendizaje\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_errors, 'o-', label='Error de Entrenamiento')\n",
        "plt.plot(train_sizes, valid_errors, 'o-', label='Error de Validación')\n",
        "plt.xlabel('Número de muestras de entrenamiento')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title('Curva de Aprendizaje - Regresión Logística')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "Path(\"figs\").mkdir(parents=True, exist_ok=True)\n",
        "plt.savefig('figs/learning_curve_logit.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# Imprimir los valores calculados\n",
        "print(\"Tamaños de entrenamiento:\", train_sizes)\n",
        "print(\"Error de entrenamiento (Log Loss):\", train_errors)\n",
        "print(\"Error de validación (Log Loss):\", valid_errors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e42dfd6c",
      "metadata": {
        "id": "e42dfd6c"
      },
      "source": [
        "**Interpretación de Resultados:**  \n",
        "1. **Sobreajuste (Overfitting):**  \n",
        "   - El sobreajuste ocurre cuando el modelo memoriza demasiado los datos de entrenamiento, logrando un error muy bajo en `X_train`, pero fallando al generalizar en `X_test`.  \n",
        "   - Un signo claro de sobreajuste es ver que el **Error de Entrenamiento** es significativamente menor que el **Error de Validación** y que ambas curvas no convergen a medida que aumenta el número de muestras de entrenamiento.\n",
        "\n",
        "2. **Curvas de Aprendizaje (Learning Curves):**  \n",
        "   - Se grafica la evolución del **Log Loss** (o la métrica que se haya elegido) en función del tamaño del set de entrenamiento. Suele mostrarse la curva de error de entrenamiento y la de validación.  \n",
        "   - Si las curvas terminan en valores cercanos (p. ej. el error de entrenamiento ≈ error de validación), se concluye que **no hay sobreajuste** y que el modelo generaliza razonablemente bien.  \n",
        "   - Si la curva de entrenamiento se mantiene muy por debajo de la curva de validación y existe una brecha notable, el modelo podría estar **sobreajustado**.  \n",
        "   - Por el contrario, si ambas curvas se mantienen en valores altos y no convergen, se podría estar frente a **subajuste** (underfitting).\n",
        "\n",
        "3. **Lectura de la Gráfica y de las Métricas:**  \n",
        "   - En la gráfica, cada eje vertical (Log Loss en este caso) indica qué tan mala es la predicción en promedio: a menor valor, mejor el desempeño del modelo.  \n",
        "   - El eje horizontal refleja el tamaño de la muestra de entrenamiento utilizada en cada punto.  \n",
        "   - Un **patrón deseable** es aquel donde, al aumentar el número de muestras, el error de entrenamiento sube ligeramente (o se mantiene estable), mientras que el error de validación baja, y ambas curvas convergen o quedan muy cercanas.\n",
        "\n",
        "4. **Conclusión sobre el Modelo:**  \n",
        "   - Si las curvas de entrenamiento y validación convergen y el error de validación es razonablemente bajo, se concluye que el modelo **generaliza bien** y no hay indicios fuertes de sobreajuste.  \n",
        "   - Si se observan divergencias claras o un error muy elevado en validación comparado con entrenamiento, se considera revisar la complejidad del modelo, la cantidad de variables o la necesidad de regularización.\n",
        "\n",
        "Al final, el análisis de las curvas de aprendizaje complementa el uso de métricas puntuales (como accuracy o ROC AUC en el conjunto de prueba) al ofrecer una **perspectiva dinámica** de cómo el modelo aprende con diferentes cantidades de datos y si logra un equilibrio adecuado entre sesgo (bias) y varianza (variance)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Punto 7: Modelo para determinar los mejores parámetros\n",
        "\n",
        "**Enunciado:**  \n",
        "Haga un tuneo del modelo para determinar los mejores parámetros, recuerde que los modelos de\n",
        "regresión logística se pueden regularizar como los de regresión lineal.\n",
        "\n"
      ],
      "metadata": {
        "id": "VIQWApM5YwnD"
      },
      "id": "VIQWApM5YwnD"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('prep', prepro),\n",
        "    ('clf', LogisticRegression(max_iter=1000, random_state=SEED, solver='saga'))\n",
        "])\n",
        "\n",
        "# Combinaciones válidas de hiperparámetros\n",
        "param_grid = [\n",
        "    {  # Para penalty='l2' (sin l1_ratio)\n",
        "        'clf__penalty': ['l2'],\n",
        "        'clf__C': [0.01, 0.1, 1]\n",
        "    },\n",
        "    {  # Para penalty='elasticnet' (con l1_ratio)\n",
        "        'clf__penalty': ['elasticnet'],\n",
        "        'clf__C': [0.01, 0.1, 1],\n",
        "        'clf__l1_ratio': [0.0, 0.5, 1.0]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Ejecutar búsqueda\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    error_score='raise'\n",
        ")\n",
        "\n",
        "# Entrenamiento\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Resultados\n",
        "print(\" Mejores hiperparámetros encontrados:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "# Evaluación en test\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"\\n Resultados con mejores parámetros:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "M0MuMPy3bkRl",
        "outputId": "cd1b2f3d-f31a-4fd8-fac4-b5c4a9129174"
      },
      "id": "M0MuMPy3bkRl",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            " Mejores hiperparámetros encontrados:\n",
            "{'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
            "\n",
            " Resultados con mejores parámetros:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94       193\n",
            "           1       0.90      0.88      0.89        99\n",
            "\n",
            "    accuracy                           0.92       292\n",
            "   macro avg       0.92      0.91      0.92       292\n",
            "weighted avg       0.92      0.92      0.92       292\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Con el objetivo de optimizar el rendimiento del modelo de regresión logística, se implementó un ajuste de hiperparámetros utilizando `GridSearchCV`. Se evaluaron distintas combinaciones de:\n",
        "\n",
        "- **Penalización (`penalty`)**: `l2`, `elasticnet`\n",
        "- **Fuerza de regularización (`C`)**: 0.01, 0.1, 1.0\n",
        "- **Proporción `l1_ratio`** (solo para `elasticnet`): 0.0, 0.5, 1.0\n",
        "\n",
        "Esto se realizó sobre un pipeline con preprocesamiento completo, que incluye:\n",
        "- Imputación y estandarización de variables numéricas.\n",
        "- Codificación one-hot de variables categóricas.\n",
        "\n",
        "El mejor conjunto de hiperparámetros encontrado fue:\n",
        "\n",
        "```python\n",
        "{'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
        "```\n",
        "El modelo entrenado y optimizado demuestra un excelente rendimiento general. La precisión y el recall son altos para ambas clases, aunque se observa un desempeño ligeramente mejor para la clase 0 (viviendas no caras), que además es la clase mayoritaria.\n",
        "\n",
        "El modelo logró una precisión del 90% y un recall del 88% en la clase 1 (viviendas caras), lo cual es destacable considerando la posible desbalance entre clases. El valor de C=0.1 permitió controlar la complejidad del modelo, reduciendo el riesgo de sobreajuste."
      ],
      "metadata": {
        "id": "U78QJPNVdqWe"
      },
      "id": "U78QJPNVdqWe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Punto 8: Análisis de la eficiencia del algoritmo\n",
        "\n",
        "**Enunciado:**  \n",
        "Haga un análisis de la eficiencia del algoritmo usando una matriz de confusión. Tenga en cuenta la\n",
        "efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen\n",
        "los errores, el tiempo y la memoria consumida. Para esto último puede usar “profvis” si trabaja con R y\n",
        "“cProfile” en Python.\n",
        "\n"
      ],
      "metadata": {
        "id": "USkFlXWigVwn"
      },
      "id": "USkFlXWigVwn"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install memory-profiler\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zPS9VAOOgoDG",
        "outputId": "1f989c8e-4971-4852-b76b-acf66116bd35"
      },
      "id": "zPS9VAOOgoDG",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory-profiler) (5.9.5)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import joblib\n",
        "\n",
        "# Usamos el mejor modelo del GridSearchCV\n",
        "model = grid.best_estimator_\n",
        "\n",
        "# Realizar predicciones sobre el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# --- Matriz de confusión ---\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = [\"No cara (0)\", \"Cara (1)\"]\n",
        "\n",
        "# Visualización con heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Valor real\")\n",
        "plt.title(\"Matriz de Confusión - Regresión Logística\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Guardar figura\n",
        "import os\n",
        "os.makedirs(\"figs\", exist_ok=True)\n",
        "plt.savefig(\"figs/matriz_confusion_logit.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# --- Guardar matriz y clasificación completa ---\n",
        "os.makedirs(\"tables\", exist_ok=True)\n",
        "pd.DataFrame(cm, index=[\"Real 0\", \"Real 1\"], columns=[\"Predicho 0\", \"Predicho 1\"]).to_csv(\"tables/confusion_matrix_logit.csv\")\n",
        "\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "pd.DataFrame(report).transpose().to_csv(\"tables/classification_report_logit.csv\")\n",
        "\n",
        "print(\"\\n Clasificación completa:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# --- Análisis de tiempo usando cProfile ---\n",
        "import cProfile\n",
        "print(\"\\n Tiempo de ejecución (cProfile):\")\n",
        "cProfile.run(\"model.predict(X_test)\")\n",
        "\n",
        "# --- Análisis de memoria usando memory_profiler ---\n",
        "try:\n",
        "    from memory_profiler import memory_usage\n",
        "\n",
        "    def predict_model():\n",
        "        model.predict(X_test)\n",
        "\n",
        "    mem_usage = memory_usage(predict_model)\n",
        "    print(f\"\\n Uso máximo de memoria: {max(mem_usage):.2f} MiB\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"\\n 'memory_profiler' no está instalado. Puedes instalarlo con: pip install memory-profiler\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11856
        },
        "id": "VG72Fhy8gejb",
        "outputId": "1c4fe0dc-0098-4214-fe5e-de952049aae0"
      },
      "id": "VG72Fhy8gejb",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Clasificación completa:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94       193\n",
            "           1       0.90      0.88      0.89        99\n",
            "\n",
            "    accuracy                           0.92       292\n",
            "   macro avg       0.92      0.91      0.92       292\n",
            "weighted avg       0.92      0.92      0.92       292\n",
            "\n",
            "\n",
            " Tiempo de ejecución (cProfile):\n",
            "         32035 function calls (31252 primitive calls) in 0.059 seconds\n",
            "\n",
            "   Ordered by: standard name\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "     1568    0.001    0.000    0.002    0.000 <frozen abc>:117(__instancecheck__)\n",
            "       86    0.000    0.000    0.000    0.000 <frozen abc>:121(__subclasscheck__)\n",
            "      260    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
            "       17    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:405(parent)\n",
            "       86    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
            "        1    0.000    0.000    0.059    0.059 <string>:1(<module>)\n",
            "        1    0.000    0.000    0.000    0.000 <string>:2(__eq__)\n",
            "       32    0.000    0.000    0.000    0.000 <string>:2(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 __init__.py:1236(__len__)\n",
            "       27    0.000    0.000    0.000    0.000 __init__.py:34(using_copy_on_write)\n",
            "        4    0.000    0.000    0.000    0.000 __init__.py:55(using_pyarrow_string_dtype)\n",
            "       43    0.000    0.000    0.000    0.000 _array_api.py:131(_single_array_device)\n",
            "       43    0.000    0.000    0.000    0.000 _array_api.py:148(device)\n",
            "       54    0.000    0.000    0.000    0.000 _array_api.py:209(_is_numpy_namespace)\n",
            "       92    0.000    0.000    0.007    0.000 _array_api.py:225(isdtype)\n",
            "       12    0.000    0.000    0.000    0.000 _array_api.py:232(<genexpr>)\n",
            "   526/94    0.003    0.000    0.007    0.000 _array_api.py:237(_isdtype_single)\n",
            "      261    0.000    0.000    0.003    0.000 _array_api.py:246(<genexpr>)\n",
            "      344    0.000    0.000    0.006    0.000 _array_api.py:261(<genexpr>)\n",
            "       91    0.000    0.000    0.001    0.000 _array_api.py:271(supported_float_dtypes)\n",
            "      139    0.000    0.000    0.000    0.000 _array_api.py:315(_check_device_cpu)\n",
            "       40    0.000    0.000    0.001    0.000 _array_api.py:320(_accept_device_cpu)\n",
            "       40    0.000    0.000    0.001    0.000 _array_api.py:321(wrapped_func)\n",
            "     1518    0.002    0.000    0.003    0.000 _array_api.py:381(__getattr__)\n",
            "       40    0.000    0.000    0.000    0.000 _array_api.py:393(bool)\n",
            "        1    0.000    0.000    0.000    0.000 _array_api.py:397(astype)\n",
            "       99    0.000    0.000    0.002    0.000 _array_api.py:401(asarray)\n",
            "        1    0.000    0.000    0.000    0.000 _array_api.py:426(reshape)\n",
            "       92    0.000    0.000    0.007    0.000 _array_api.py:441(isdtype)\n",
            "       43    0.000    0.000    0.000    0.000 _array_api.py:459(_remove_non_arrays)\n",
            "      282    0.000    0.000    0.001    0.000 _array_api.py:497(get_namespace)\n",
            "       50    0.000    0.000    0.001    0.000 _array_api.py:818(_asarray_with_order)\n",
            "        4    0.000    0.000    0.000    0.000 _array_api.py:89(_check_array_api_dispatch)\n",
            "        1    0.000    0.000    0.000    0.000 _array_api.py:913(indexing_dtype)\n",
            "        3    0.000    0.000    0.000    0.000 _available_if.py:27(_check)\n",
            "        3    0.000    0.000    0.000    0.000 _available_if.py:39(__get__)\n",
            "        2    0.000    0.000    0.000    0.000 _base.py:107(_transform_indicator)\n",
            "        6    0.000    0.000    0.000    0.000 _base.py:113(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 _base.py:120(_concatenate_indicator)\n",
            "        6    0.000    0.000    0.000    0.000 _base.py:124(shape)\n",
            "       10    0.000    0.000    0.001    0.000 _base.py:1303(_get_index_dtype)\n",
            "      161    0.000    0.000    0.000    0.000 _base.py:1335(issparse)\n",
            "       14    0.000    0.000    0.000    0.000 _base.py:148(__sklearn_tags__)\n",
            "        2    0.000    0.000    0.000    0.000 _base.py:29(_check_inputs_dtype)\n",
            "       20    0.000    0.000    0.000    0.000 _base.py:294(nnz)\n",
            "        4    0.000    0.000    0.000    0.000 _base.py:314(format)\n",
            "        2    0.000    0.000    0.009    0.005 _base.py:319(_validate_input)\n",
            "        1    0.000    0.000    0.001    0.001 _base.py:329(decision_function)\n",
            "        1    0.000    0.000    0.001    0.001 _base.py:359(predict)\n",
            "        1    0.000    0.000    0.000    0.000 _base.py:377(__len__)\n",
            "        1    0.000    0.000    0.000    0.000 _base.py:381(asformat)\n",
            "        1    0.000    0.000    0.000    0.000 _base.py:544(_matmul_dispatch)\n",
            "        2    0.000    0.000    0.011    0.005 _base.py:591(transform)\n",
            "        1    0.000    0.000    0.000    0.000 _base.py:665(__matmul__)\n",
            "       16    0.000    0.000    0.000    0.000 _base.py:69(ndim)\n",
            "       11    0.000    0.000    0.000    0.000 _base.py:73(_shape_as_2d)\n",
            "       14    0.000    0.000    0.001    0.000 _base.py:740(__sklearn_tags__)\n",
            "        8    0.000    0.000    0.000    0.000 _bunch.py:30(__init__)\n",
            "       10    0.000    0.000    0.000    0.000 _bunch.py:36(__getitem__)\n",
            "        6    0.000    0.000    0.000    0.000 _bunch.py:55(__getattr__)\n",
            "        1    0.000    0.000    0.049    0.049 _column_transformer.py:1033(transform)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:1079(<listcomp>)\n",
            "       81    0.000    0.000    0.000    0.000 _column_transformer.py:1086(<genexpr>)\n",
            "        1    0.000    0.000    0.003    0.003 _column_transformer.py:1116(_hstack)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:1135(<listcomp>)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:1259(_get_empty_routing)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:1268(<dictcomp>)\n",
            "        2    0.000    0.000    0.000    0.000 _column_transformer.py:1269(<dictcomp>)\n",
            "        3    0.000    0.000    0.009    0.003 _column_transformer.py:1319(__sklearn_tags__)\n",
            "        6    0.000    0.000    0.009    0.001 _column_transformer.py:1322(<genexpr>)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:1335(_check_X)\n",
            "        6    0.000    0.000    0.000    0.000 _column_transformer.py:1346(_is_empty_column_selection)\n",
            "       12    0.000    0.000    0.000    0.000 _column_transformer.py:1357(<genexpr>)\n",
            "        3    0.000    0.000    0.000    0.000 _column_transformer.py:1686(_with_dtype_warning_enabled_set_to)\n",
            "        9    0.000    0.000    0.000    0.000 _column_transformer.py:437(_iter)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:472(<listcomp>)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:589(named_transformers_)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:598(<dictcomp>)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:758(_validate_output)\n",
            "        1    0.000    0.000    0.000    0.000 _column_transformer.py:763(<listcomp>)\n",
            "        1    0.000    0.000    0.044    0.044 _column_transformer.py:838(_call_func_on_transformers)\n",
            "        8    0.000    0.000    0.000    0.000 _compressed.py:114(_getnnz)\n",
            "        1    0.000    0.000    0.000    0.000 _compressed.py:1162(tocoo)\n",
            "        1    0.000    0.000    0.000    0.000 _compressed.py:1210(has_canonical_format)\n",
            "        1    0.000    0.000    0.000    0.000 _compressed.py:1233(has_canonical_format)\n",
            "        1    0.000    0.000    0.000    0.000 _compressed.py:1239(sum_duplicates)\n",
            "        1    0.000    0.000    0.000    0.000 _compressed.py:1270(has_sorted_indices)\n",
            "        2    0.000    0.000    0.000    0.000 _compressed.py:1295(prune)\n",
            "        2    0.000    0.000    0.000    0.000 _compressed.py:135(check_format)\n",
            "        2    0.000    0.000    0.000    0.000 _compressed.py:27(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 _compressed.py:484(_matmul_vector)\n",
            "        4    0.000    0.000    0.000    0.000 _config.py:214(config_context)\n",
            "      306    0.000    0.000    0.000    0.000 _config.py:27(_get_threadlocal_config)\n",
            "      302    0.000    0.000    0.001    0.000 _config.py:35(get_config)\n",
            "        4    0.000    0.000    0.000    0.000 _config.py:60(set_config)\n",
            "        1    0.000    0.000    0.002    0.002 _construct.py:698(hstack)\n",
            "        3    0.000    0.000    0.000    0.000 _construct.py:739(<genexpr>)\n",
            "        1    0.000    0.000    0.002    0.002 _construct.py:903(_block)\n",
            "        2    0.000    0.000    0.000    0.000 _construct.py:913(<genexpr>)\n",
            "        2    0.000    0.000    0.000    0.000 _construct.py:926(<genexpr>)\n",
            "        3    0.000    0.000    0.000    0.000 _construct.py:968(<genexpr>)\n",
            "        1    0.000    0.000    0.000    0.000 _construct.py:970(<listcomp>)\n",
            "        2    0.000    0.000    0.000    0.000 _coo.py:101(row)\n",
            "        2    0.000    0.000    0.000    0.000 _coo.py:117(col)\n",
            "       12    0.000    0.000    0.000    0.000 _coo.py:161(_getnnz)\n",
            "       36    0.000    0.000    0.000    0.000 _coo.py:164(<genexpr>)\n",
            "       36    0.000    0.000    0.000    0.000 _coo.py:168(<genexpr>)\n",
            "        4    0.000    0.000    0.001    0.000 _coo.py:185(_check)\n",
            "       12    0.000    0.000    0.000    0.000 _coo.py:198(<genexpr>)\n",
            "      4/3    0.000    0.000    0.001    0.000 _coo.py:27(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 _coo.py:318(tocsr)\n",
            "        1    0.000    0.000    0.000    0.000 _coo.py:350(_coo_to_compressed)\n",
            "        6    0.000    0.000    0.000    0.000 _coo.py:59(<genexpr>)\n",
            "        3    0.000    0.000    0.000    0.000 _coo.py:91(<genexpr>)\n",
            "        8    0.000    0.000    0.000    0.000 _csr.py:160(_swap)\n",
            "        1    0.000    0.000    0.001    0.001 _data.py:1044(transform)\n",
            "       11    0.000    0.000    0.000    0.000 _data.py:1130(__sklearn_tags__)\n",
            "        6    0.000    0.000    0.000    0.000 _data.py:21(__init__)\n",
            "       23    0.000    0.000    0.000    0.000 _data.py:24(dtype)\n",
            "        4    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\n",
            "        4    0.000    0.000    0.000    0.000 _dtype.py:336(_name_includes_bit_suffix)\n",
            "        4    0.000    0.000    0.000    0.000 _dtype.py:352(_name_get)\n",
            "       86    0.000    0.000    0.003    0.000 _encode.py:116(_extract_missing)\n",
            "       86    0.000    0.000    0.002    0.000 _encode.py:132(<setcomp>)\n",
            "       43    0.000    0.000    0.001    0.000 _encode.py:157(__init__)\n",
            "       43    0.000    0.000    0.007    0.000 _encode.py:170(_map_to_integer)\n",
            "       43    0.000    0.000    0.000    0.000 _encode.py:173(<dictcomp>)\n",
            "       43    0.002    0.000    0.002    0.000 _encode.py:174(<listcomp>)\n",
            "       43    0.000    0.000    0.011    0.000 _encode.py:203(_encode)\n",
            "       43    0.001    0.000    0.010    0.000 _encode.py:246(_check_unknown)\n",
            "      876    0.000    0.000    0.000    0.000 _encode.py:285(is_valid)\n",
            "        3    0.000    0.000    0.001    0.000 _encode.py:296(<listcomp>)\n",
            "        1    0.000    0.000    0.027    0.027 _encoders.py:1000(transform)\n",
            "        1    0.001    0.001    0.026    0.026 _encoders.py:190(_transform)\n",
            "        1    0.000    0.000    0.004    0.004 _encoders.py:35(_check_X)\n",
            "        1    0.000    0.000    0.000    0.000 _encoders.py:406(_map_infrequent_categories)\n",
            "        4    0.000    0.000    0.000    0.000 _encoders.py:458(__sklearn_tags__)\n",
            "        2    0.000    0.000    0.000    0.000 _function_base_impl.py:5762(_append_dispatcher)\n",
            "        2    0.000    0.000    0.000    0.000 _function_base_impl.py:5766(append)\n",
            "       45    0.000    0.000    0.004    0.000 _indexing.py:179(_safe_indexing)\n",
            "       43    0.000    0.000    0.000    0.000 _indexing.py:27(_array_indexing)\n",
            "        2    0.000    0.000    0.003    0.001 _indexing.py:39(_pandas_indexing)\n",
            "       45    0.000    0.000    0.000    0.000 _indexing.py:95(_determine_key_type)\n",
            "        4    0.000    0.000    0.000    0.000 _logistic.py:1460(__sklearn_tags__)\n",
            "        4    0.000    0.000    0.000    0.000 _mask.py:14(_get_dense_mask)\n",
            "        4    0.000    0.000    0.000    0.000 _mask.py:38(_get_mask)\n",
            "        1    0.000    0.000    0.000    0.000 _matrix.py:12(_coo_container)\n",
            "        1    0.000    0.000    0.000    0.000 _matrix.py:22(_csr_container)\n",
            "       29    0.000    0.000    0.000    0.000 _matrix.py:64(get_shape)\n",
            "        5    0.000    0.000    0.000    0.000 _metadata_requests.py:119(_routing_enabled)\n",
            "        3    0.000    0.000    0.000    0.000 _metadata_requests.py:133(_raise_for_params)\n",
            "        2    0.000    0.000    0.000    0.000 _metadata_requests.py:1522(process_routing)\n",
            "        2    0.000    0.000    0.000    0.000 _metadata_requests.py:1565(EmptyRequest)\n",
            "        4    0.000    0.000    0.000    0.000 _metadata_requests.py:1569(__getitem__)\n",
            "        4    0.000    0.000    0.000    0.000 _metadata_requests.py:1570(<dictcomp>)\n",
            "       13    0.000    0.000    0.000    0.000 _methods.py:42(_amax)\n",
            "       10    0.000    0.000    0.000    0.000 _methods.py:46(_amin)\n",
            "        2    0.000    0.000    0.000    0.000 _methods.py:50(_sum)\n",
            "        4    0.000    0.000    0.000    0.000 _methods.py:58(_any)\n",
            "        2    0.000    0.000    0.000    0.000 _methods.py:67(_all)\n",
            "       18    0.000    0.000    0.000    0.000 _missing.py:47(is_pandas_na)\n",
            "      743    0.001    0.000    0.003    0.000 _missing.py:9(is_scalar_nan)\n",
            "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:109(compute_batch_size)\n",
            "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:203(in_main_thread)\n",
            "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:220(effective_n_jobs)\n",
            "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:309(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 _parallel_backends.py:46(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:530(configure)\n",
            "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:545(effective_n_jobs)\n",
            "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:630(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:90(configure)\n",
            "        7    0.000    0.000    0.000    0.000 _set_output.py:193(supported_outputs)\n",
            "        7    0.000    0.000    0.000    0.000 _set_output.py:233(_get_output_config)\n",
            "        5    0.000    0.000    0.000    0.000 _set_output.py:268(_wrap_data_with_container)\n",
            "      5/1    0.000    0.000    0.049    0.049 _set_output.py:317(wrapped)\n",
            "        2    0.000    0.000    0.000    0.000 _sputils.py:111(getdtype)\n",
            "        2    0.000    0.000    0.000    0.000 _sputils.py:137(getdata)\n",
            "       11    0.000    0.000    0.000    0.000 _sputils.py:149(get_index_dtype)\n",
            "        1    0.000    0.000    0.000    0.000 _sputils.py:213(isscalarlike)\n",
            "        2    0.000    0.000    0.000    0.000 _sputils.py:218(isintlike)\n",
            "        1    0.000    0.000    0.000    0.000 _sputils.py:24(upcast)\n",
            "        4    0.000    0.000    0.000    0.000 _sputils.py:240(isshape)\n",
            "        1    0.000    0.000    0.000    0.000 _sputils.py:269(isdense)\n",
            "        6    0.000    0.000    0.000    0.000 _sputils.py:296(check_shape)\n",
            "       18    0.000    0.000    0.000    0.000 _sputils.py:327(<genexpr>)\n",
            "       18    0.000    0.000    0.000    0.000 _sputils.py:336(<genexpr>)\n",
            "        1    0.000    0.000    0.000    0.000 _sputils.py:58(upcast_char)\n",
            "        4    0.000    0.000    0.000    0.000 _sputils.py:95(to_native)\n",
            "       32    0.000    0.000    0.000    0.000 _tags.py:137(<lambda>)\n",
            "       42    0.002    0.000    0.010    0.000 _tags.py:303(_find_tags_provider)\n",
            "      930    0.000    0.000    0.000    0.000 _tags.py:340(<genexpr>)\n",
            "    42/16    0.000    0.000    0.012    0.001 _tags.py:367(get_tags)\n",
            "        3    0.000    0.000    0.000    0.000 _ufunc_config.py:400(__init__)\n",
            "        3    0.000    0.000    0.000    0.000 _ufunc_config.py:410(__enter__)\n",
            "        3    0.000    0.000    0.000    0.000 _ufunc_config.py:426(__exit__)\n",
            "        4    0.000    0.000    0.000    0.000 _util.py:225(_prune_array)\n",
            "        2    0.000    0.000    0.000    0.000 _validators.py:226(validate_bool_kwarg)\n",
            "        8    0.000    0.000    0.002    0.000 accessor.py:220(__get__)\n",
            "        8    0.000    0.000    0.002    0.000 accessor.py:246(_validate)\n",
            "       16    0.000    0.000    0.000    0.000 accessor.py:248(<genexpr>)\n",
            "        8    0.000    0.000    0.002    0.000 accessor.py:29(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 algorithms.py:1131(take)\n",
            "        2    0.000    0.000    0.000    0.000 algorithms.py:1667(map_array)\n",
            "        2    0.000    0.000    0.000    0.000 apply.py:121(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 apply.py:1377(__init__)\n",
            "        2    0.000    0.000    0.001    0.000 apply.py:1409(apply)\n",
            "        2    0.000    0.000    0.001    0.000 apply.py:1482(apply_standard)\n",
            "        4    0.000    0.000    0.000    0.000 astype.py:249(astype_is_view)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:1146(take)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:1176(_maybe_disallow_fill)\n",
            "        6    0.000    0.000    0.000    0.000 base.py:1671(name)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:1979(nlevels)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:2744(inferred_type)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:2776(_is_multi)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:378(interleaved_dtype)\n",
            "        4    0.000    0.000    0.001    0.000 base.py:3820(get_indexer)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:3955(_get_indexer)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:397(ensure_np_dtype)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:3996(_check_indexing_method)\n",
            "       42    0.000    0.000    0.000    0.000 base.py:419(__sklearn_tags__)\n",
            "        2    0.000    0.000    0.001    0.000 base.py:4323(reindex)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:4436(_wrap_reindex_result)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:4440(_maybe_preserve_names)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:456(_engine_type)\n",
            "        4    0.000    0.000    0.001    0.000 base.py:475(__new__)\n",
            "       38    0.000    0.000    0.000    0.000 base.py:5144(_values)\n",
            "        6    0.000    0.000    0.000    0.000 base.py:5170(_get_engine_target)\n",
            "       11    0.000    0.000    0.000    0.000 base.py:5323(__contains__)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:539(__sklearn_tags__)\n",
            "       11    0.000    0.000    0.000    0.000 base.py:5437(_can_hold_identifiers_and_holds_name)\n",
            "       16    0.000    0.000    0.000    0.000 base.py:549(find)\n",
            "        6    0.000    0.000    0.000    0.000 base.py:5552(equals)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:591(_ensure_array)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:609(_dtype_to_subclass)\n",
            "        2    0.000    0.000    0.001    0.000 base.py:6162(get_indexer_for)\n",
            "        2    0.000    0.000    0.002    0.001 base.py:6186(_get_indexer_strict)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:6219(_raise_if_missing)\n",
            "       10    0.000    0.000    0.000    0.000 base.py:6312(_index_as_unique)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:6324(_maybe_downcast_for_indexing)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:6394(_should_compare)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:6415(_is_comparable_dtype)\n",
            "        6    0.000    0.000    0.000    0.000 base.py:649(_simple_new)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:6679(_maybe_cast_listlike_indexer)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:74(__len__)\n",
            "       44    0.000    0.000    0.001    0.000 base.py:7593(ensure_index)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:7652(ensure_has_len)\n",
            "       22    0.000    0.000    0.000    0.000 base.py:7688(maybe_extract_name)\n",
            "        4    0.000    0.000    0.000    0.000 base.py:7723(_unpack_nested_dtype)\n",
            "        6    0.000    0.000    0.000    0.000 base.py:791(is_)\n",
            "        8    0.000    0.000    0.000    0.000 base.py:82(shape)\n",
            "        6    0.000    0.000    0.000    0.000 base.py:831(_reset_identity)\n",
            "       16    0.000    0.000    0.000    0.000 base.py:836(__iter__)\n",
            "       24    0.000    0.000    0.000    0.000 base.py:84(<genexpr>)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:842(_engine)\n",
            "       32    0.000    0.000    0.000    0.000 base.py:858(__sklearn_tags__)\n",
            "       18    0.000    0.000    0.000    0.000 base.py:86(_validate_set_axis)\n",
            "        2    0.000    0.000    0.000    0.000 base.py:891(_map_values)\n",
            "      152    0.000    0.000    0.000    0.000 base.py:909(__len__)\n",
            "        3    0.000    0.000    0.000    0.000 base.py:915(__array__)\n",
            "        6    0.000    0.000    0.000    0.000 base.py:974(dtype)\n",
            "        3    0.000    0.000    0.000    0.000 blocks.py:1287(take_nd)\n",
            "        2    0.000    0.000    0.000    0.000 blocks.py:214(is_extension)\n",
            "        4    0.000    0.000    0.000    0.000 blocks.py:2586(get_values)\n",
            "       18    0.000    0.000    0.000    0.000 blocks.py:2645(maybe_coerce_values)\n",
            "        4    0.000    0.000    0.000    0.000 blocks.py:266(mgr_locs)\n",
            "       18    0.000    0.000    0.000    0.000 blocks.py:2674(get_block_type)\n",
            "       18    0.000    0.000    0.000    0.000 blocks.py:2716(new_block)\n",
            "        3    0.000    0.000    0.000    0.000 blocks.py:292(make_block_same_class)\n",
            "        5    0.000    0.000    0.000    0.000 blocks.py:718(dtype)\n",
            "        4    0.000    0.000    0.000    0.000 cast.py:1157(maybe_infer_to_datetimelike)\n",
            "        2    0.000    0.000    0.000    0.000 cast.py:1392(np_find_common_type)\n",
            "        2    0.000    0.000    0.000    0.000 cast.py:1433(find_common_type)\n",
            "        6    0.000    0.000    0.000    0.000 cast.py:1463(<genexpr>)\n",
            "        4    0.000    0.000    0.000    0.000 cast.py:1472(<genexpr>)\n",
            "        4    0.000    0.000    0.000    0.000 cast.py:1474(<genexpr>)\n",
            "        6    0.000    0.000    0.000    0.000 cast.py:1479(<genexpr>)\n",
            "        4    0.000    0.000    0.000    0.000 cast.py:551(maybe_promote)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:1040(needs_i8_conversion)\n",
            "        4    0.000    0.000    0.000    0.000 common.py:1081(is_numeric_dtype)\n",
            "        4    0.000    0.000    0.000    0.000 common.py:1122(<lambda>)\n",
            "       80    0.000    0.000    0.001    0.000 common.py:1198(is_bool_dtype)\n",
            "       15    0.000    0.000    0.000    0.000 common.py:121(classes)\n",
            "       15    0.000    0.000    0.000    0.000 common.py:123(<lambda>)\n",
            "        4    0.000    0.000    0.000    0.000 common.py:126(_classes_and_not_datetimelike)\n",
            "       80    0.000    0.000    0.000    0.000 common.py:1277(is_extension_array_dtype)\n",
            "        4    0.000    0.000    0.000    0.000 common.py:131(<lambda>)\n",
            "        8    0.000    0.000    0.000    0.000 common.py:1331(is_ea_or_datetimelike_dtype)\n",
            "       15    0.000    0.000    0.000    0.000 common.py:137(is_object_dtype)\n",
            "        4    0.000    0.000    0.000    0.000 common.py:1375(_is_dtype)\n",
            "       84    0.000    0.000    0.000    0.000 common.py:1399(_get_dtype)\n",
            "       19    0.000    0.000    0.000    0.000 common.py:1434(_is_dtype_type)\n",
            "       18    0.000    0.000    0.000    0.000 common.py:1571(validate_all_hashable)\n",
            "       36    0.000    0.000    0.000    0.000 common.py:1590(<genexpr>)\n",
            "       16    0.000    0.000    0.001    0.000 common.py:1596(pandas_dtype)\n",
            "        6    0.000    0.000    0.000    0.000 common.py:231(asarray_tuplesafe)\n",
            "        4    0.000    0.000    0.000    0.000 common.py:311(is_null_slice)\n",
            "        4    0.000    0.000    0.000    0.000 common.py:372(apply_if_callable)\n",
            "       18    0.000    0.000    0.000    0.000 common.py:568(require_length_match)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:97(is_bool_indexer)\n",
            "       18    0.000    0.000    0.000    0.000 config.py:127(_get_single_key)\n",
            "       18    0.000    0.000    0.000    0.000 config.py:145(_get_option)\n",
            "       18    0.000    0.000    0.000    0.000 config.py:617(_select_options)\n",
            "       18    0.000    0.000    0.000    0.000 config.py:635(_get_root)\n",
            "       18    0.000    0.000    0.000    0.000 config.py:649(_get_deprecated_option)\n",
            "       18    0.000    0.000    0.000    0.000 config.py:676(_translate_key)\n",
            "       22    0.000    0.000    0.000    0.000 construction.py:416(extract_array)\n",
            "       40    0.000    0.000    0.000    0.000 construction.py:481(ensure_wrapped_if_datetimelike)\n",
            "       22    0.000    0.000    0.001    0.000 construction.py:517(sanitize_array)\n",
            "       22    0.000    0.000    0.000    0.000 construction.py:696(_sanitize_ndim)\n",
            "       22    0.000    0.000    0.000    0.000 construction.py:735(_sanitize_str_dtypes)\n",
            "       22    0.000    0.000    0.000    0.000 construction.py:758(_maybe_repeat)\n",
            "       16    0.000    0.000    0.000    0.000 construction.py:769(_try_cast)\n",
            "        1    0.000    0.000    0.000    0.000 context.py:237(get_context)\n",
            "        5    0.000    0.000    0.000    0.000 contextlib.py:104(__init__)\n",
            "        5    0.000    0.000    0.000    0.000 contextlib.py:132(__enter__)\n",
            "        5    0.000    0.000    0.011    0.002 contextlib.py:141(__exit__)\n",
            "        5    0.000    0.000    0.000    0.000 contextlib.py:299(helper)\n",
            "       26    0.000    0.000    0.000    0.000 contextlib.py:440(__init__)\n",
            "       26    0.000    0.000    0.000    0.000 contextlib.py:443(__enter__)\n",
            "       26    0.000    0.000    0.000    0.000 contextlib.py:446(__exit__)\n",
            "        1    0.000    0.000    0.000    0.000 contextlib.py:763(__init__)\n",
            "    67/18    0.000    0.000    0.001    0.000 copy.py:128(deepcopy)\n",
            "       44    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)\n",
            "        5    0.000    0.000    0.000    0.000 copy.py:201(_deepcopy_list)\n",
            "        6    0.000    0.000    0.000    0.000 copy.py:210(_deepcopy_tuple)\n",
            "        6    0.000    0.000    0.000    0.000 copy.py:211(<listcomp>)\n",
            "        6    0.000    0.000    0.000    0.000 copy.py:227(_deepcopy_dict)\n",
            "       23    0.000    0.000    0.000    0.000 copy.py:243(_keep_alive)\n",
            "        6    0.000    0.000    0.001    0.000 copy.py:259(_reconstruct)\n",
            "       12    0.000    0.000    0.000    0.000 copy.py:264(<genexpr>)\n",
            "        6    0.000    0.000    0.000    0.000 copyreg.py:104(__newobj__)\n",
            "       50    0.000    0.000    0.000    0.000 deprecation.py:148(_deprecate_force_all_finite)\n",
            "        1    0.000    0.000    0.000    0.000 disk.py:42(memstr_to_bytes)\n",
            "        1    0.000    0.000    0.000    0.000 extmath.py:153(safe_sparse_dot)\n",
            "        2    0.000    0.000    0.000    0.000 fixes.py:83(_object_dtype_isnan)\n",
            "       20    0.000    0.000    0.000    0.000 flags.py:51(__init__)\n",
            "        4    0.000    0.000    0.000    0.000 flags.py:55(allows_duplicate_labels)\n",
            "        4    0.000    0.000    0.000    0.000 flags.py:87(allows_duplicate_labels)\n",
            "        2    0.000    0.000    0.000    0.000 frame.py:1030(axes)\n",
            "       18    0.000    0.000    0.000    0.000 frame.py:1047(shape)\n",
            "        4    0.000    0.000    0.000    0.000 frame.py:1111(_values)\n",
            "        2    0.000    0.000    0.000    0.000 frame.py:12590(values)\n",
            "        2    0.000    0.000    0.000    0.000 frame.py:659(_constructor_from_mgr)\n",
            "        1    0.000    0.000    0.000    0.000 fromnumeric.py:105(_take_dispatcher)\n",
            "        1    0.000    0.000    0.000    0.000 fromnumeric.py:109(take)\n",
            "        4    0.000    0.000    0.000    0.000 fromnumeric.py:1842(_ravel_dispatcher)\n",
            "        4    0.000    0.000    0.000    0.000 fromnumeric.py:1846(ravel)\n",
            "        3    0.000    0.000    0.000    0.000 fromnumeric.py:1955(_nonzero_dispatcher)\n",
            "        3    0.000    0.000    0.000    0.000 fromnumeric.py:1959(nonzero)\n",
            "        1    0.000    0.000    0.000    0.000 fromnumeric.py:209(_reshape_dispatcher)\n",
            "        1    0.000    0.000    0.000    0.000 fromnumeric.py:214(reshape)\n",
            "        6    0.000    0.000    0.000    0.000 fromnumeric.py:2250(_sum_dispatcher)\n",
            "        6    0.000    0.000    0.000    0.000 fromnumeric.py:2255(sum)\n",
            "        3    0.000    0.000    0.000    0.000 fromnumeric.py:2395(_any_dispatcher)\n",
            "        3    0.000    0.000    0.000    0.000 fromnumeric.py:2400(any)\n",
            "       43    0.000    0.000    0.000    0.000 fromnumeric.py:2508(_all_dispatcher)\n",
            "       43    0.000    0.000    0.001    0.000 fromnumeric.py:2513(all)\n",
            "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2605(_cumsum_dispatcher)\n",
            "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2609(cumsum)\n",
            "        2    0.000    0.000    0.000    0.000 fromnumeric.py:3263(_ndim_dispatcher)\n",
            "        2    0.000    0.000    0.000    0.000 fromnumeric.py:3267(ndim)\n",
            "        1    0.000    0.000    0.000    0.000 fromnumeric.py:41(_wrapit)\n",
            "        2    0.000    0.000    0.000    0.000 fromnumeric.py:433(_repeat_dispatcher)\n",
            "        2    0.000    0.000    0.000    0.000 fromnumeric.py:437(repeat)\n",
            "       11    0.000    0.000    0.000    0.000 fromnumeric.py:51(_wrapfunc)\n",
            "        6    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\n",
            "        6    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
            "       46    0.000    0.000    0.001    0.000 fromnumeric.py:89(_wrapreduction_any_all)\n",
            "       46    0.000    0.000    0.000    0.000 fromnumeric.py:91(<dictcomp>)\n",
            "        2    0.000    0.000    0.000    0.000 function.py:64(__call__)\n",
            "       44    0.000    0.000    0.001    0.000 functools.py:35(update_wrapper)\n",
            "       42    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
            "        4    0.000    0.000    0.000    0.000 generic.py:2149(__array__)\n",
            "       20    0.000    0.000    0.000    0.000 generic.py:278(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 generic.py:339(_from_mgr)\n",
            "        4    0.000    0.000    0.000    0.000 generic.py:363(attrs)\n",
            "      190    0.000    0.000    0.000    0.000 generic.py:37(_check)\n",
            "        8    0.000    0.000    0.000    0.000 generic.py:405(flags)\n",
            "      190    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\n",
            "       16    0.000    0.000    0.001    0.000 generic.py:511(_validate_dtype)\n",
            "        2    0.000    0.000    0.001    0.000 generic.py:5663(_reindex_with_indexers)\n",
            "       18    0.000    0.000    0.000    0.000 generic.py:572(_get_axis_number)\n",
            "        2    0.000    0.000    0.000    0.000 generic.py:580(_get_axis_name)\n",
            "       12    0.000    0.000    0.000    0.000 generic.py:586(_get_axis)\n",
            "        2    0.000    0.000    0.000    0.000 generic.py:592(_get_block_manager_axis)\n",
            "        4    0.000    0.000    0.000    0.000 generic.py:6236(__finalize__)\n",
            "    33/29    0.000    0.000    0.001    0.000 generic.py:6284(__getattr__)\n",
            "       18    0.000    0.000    0.000    0.000 generic.py:6301(__setattr__)\n",
            "       16    0.000    0.000    0.003    0.000 generic.py:6432(dtypes)\n",
            "       27    0.000    0.000    0.000    0.000 generic.py:667(_info_axis)\n",
            "        4    0.000    0.000    0.000    0.000 generic.py:696(ndim)\n",
            "       18    0.000    0.000    0.000    0.000 generic.py:807(_set_axis)\n",
            "       22    0.000    0.000    0.000    0.000 getlimits.py:688(__init__)\n",
            "       11    0.000    0.000    0.000    0.000 getlimits.py:699(min)\n",
            "       11    0.000    0.000    0.000    0.000 getlimits.py:712(max)\n",
            "        2    0.000    0.000    0.003    0.001 indexing.py:1004(_getitem_tuple_same_dim)\n",
            "        2    0.000    0.000    0.000    0.000 indexing.py:1032(_getitem_lowerdim)\n",
            "        2    0.000    0.000    0.003    0.001 indexing.py:1176(__getitem__)\n",
            "        6    0.000    0.000    0.000    0.000 indexing.py:1180(<genexpr>)\n",
            "        6    0.000    0.000    0.000    0.000 indexing.py:1181(<genexpr>)\n",
            "        6    0.000    0.000    0.000    0.000 indexing.py:1226(_validate_key)\n",
            "        2    0.000    0.000    0.000    0.000 indexing.py:1251(_is_scalar_access)\n",
            "        2    0.000    0.000    0.000    0.000 indexing.py:1285(_multi_take_opportunity)\n",
            "        4    0.000    0.000    0.000    0.000 indexing.py:1303(<genexpr>)\n",
            "        2    0.000    0.000    0.002    0.001 indexing.py:1334(_getitem_iterable)\n",
            "        2    0.000    0.000    0.003    0.001 indexing.py:1365(_getitem_tuple)\n",
            "        2    0.000    0.000    0.003    0.001 indexing.py:1397(_getitem_axis)\n",
            "        2    0.000    0.000    0.002    0.001 indexing.py:1532(_get_listlike_indexer)\n",
            "        2    0.000    0.000    0.000    0.000 indexing.py:161(iloc)\n",
            "        4    0.000    0.000    0.000    0.000 indexing.py:2738(is_label_like)\n",
            "        2    0.000    0.000    0.000    0.000 indexing.py:2765(check_dict_or_set_indexers)\n",
            "        6    0.000    0.000    0.000    0.000 indexing.py:2772(<genexpr>)\n",
            "        6    0.000    0.000    0.000    0.000 indexing.py:2781(<genexpr>)\n",
            "        4    0.000    0.000    0.000    0.000 indexing.py:305(loc)\n",
            "        4    0.000    0.000    0.000    0.000 indexing.py:935(_expand_ellipsis)\n",
            "       12    0.000    0.000    0.000    0.000 indexing.py:941(<genexpr>)\n",
            "        2    0.000    0.000    0.000    0.000 indexing.py:957(_validate_tuple_indexer)\n",
            "        2    0.000    0.000    0.000    0.000 indexing.py:974(_is_nested_tuple_indexer)\n",
            "        6    0.000    0.000    0.000    0.000 indexing.py:981(<genexpr>)\n",
            "        4    0.000    0.000    0.000    0.000 indexing.py:992(_validate_key_length)\n",
            "        2    0.000    0.000    0.000    0.000 inference.py:195(is_array_like)\n",
            "        2    0.000    0.000    0.000    0.000 inference.py:273(is_dict_like)\n",
            "        4    0.000    0.000    0.000    0.000 inference.py:300(<genexpr>)\n",
            "       56    0.000    0.000    0.000    0.000 inference.py:334(is_hashable)\n",
            "       12    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
            "        1    0.000    0.000    0.000    0.000 logger.py:67(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:1633(as_array)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:1707(_interleave)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:1721(<listcomp>)\n",
            "       18    0.000    0.000    0.000    0.000 managers.py:180(blknos)\n",
            "       18    0.000    0.000    0.000    0.000 managers.py:1837(__init__)\n",
            "       18    0.000    0.000    0.000    0.000 managers.py:1863(from_array)\n",
            "       14    0.000    0.000    0.000    0.000 managers.py:1940(_block)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:196(blklocs)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:1993(dtype)\n",
            "       34    0.000    0.000    0.000    0.000 managers.py:2004(internal_values)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:2320(_preprocess_slice_or_indexer)\n",
            "       18    0.000    0.000    0.000    0.000 managers.py:236(set_axis)\n",
            "        4    0.000    0.000    0.000    0.000 managers.py:241(is_single_block)\n",
            "        4    0.000    0.000    0.000    0.000 managers.py:246(items)\n",
            "       16    0.000    0.000    0.000    0.000 managers.py:287(get_dtypes)\n",
            "       16    0.000    0.000    0.000    0.000 managers.py:288(<listcomp>)\n",
            "        2    0.000    0.000    0.001    0.000 managers.py:623(reindex_indexer)\n",
            "        2    0.000    0.000    0.001    0.000 managers.py:708(_slice_take_blocks_ax0)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:913(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:948(from_blocks)\n",
            "        4    0.000    0.000    0.000    0.000 missing.py:1073(clean_reindex_fill_method)\n",
            "       48    0.000    0.000    0.000    0.000 multiarray.py:1089(copyto)\n",
            "        3    0.000    0.000    0.000    0.000 multiarray.py:1404(may_share_memory)\n",
            "        2    0.000    0.000    0.000    0.000 multiarray.py:161(concatenate)\n",
            "        2    0.000    0.000    0.000    0.000 multiarray.py:361(where)\n",
            "       18    0.000    0.000    0.000    0.000 multiarray.py:556(can_cast)\n",
            "        4    0.000    0.000    0.000    0.000 multiarray.py:678(result_type)\n",
            "        2    0.000    0.000    0.000    0.000 multiarray.py:83(empty_like)\n",
            "        2    0.000    0.000    0.000    0.000 nanops.py:482(nanany)\n",
            "       42    0.000    0.000    0.001    0.000 numeric.py:143(ones)\n",
            "        7    0.000    0.000    0.000    0.000 numeric.py:1918(isscalar)\n",
            "        6    0.000    0.000    0.000    0.000 numeric.py:300(full)\n",
            "        2    0.000    0.000    0.000    0.000 numeric.py:654(_flatnonzero_dispatcher)\n",
            "        2    0.000    0.000    0.000    0.000 numeric.py:658(flatnonzero)\n",
            "       16    0.000    0.000    0.000    0.000 numerictypes.py:288(issubclass_)\n",
            "        8    0.000    0.000    0.000    0.000 numerictypes.py:470(issubdtype)\n",
            "        2    0.000    0.000    0.000    0.000 parallel.py:107(delayed_function)\n",
            "       12    0.000    0.000    0.000    0.000 parallel.py:110(_get_config_param)\n",
            "        2    0.000    0.000    0.000    0.000 parallel.py:117(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 parallel.py:1197(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 parallel.py:121(with_config)\n",
            "        1    0.000    0.000    0.000    0.000 parallel.py:1242(<dictcomp>)\n",
            "        2    0.000    0.000    0.041    0.020 parallel.py:125(__call__)\n",
            "      2/1    0.000    0.000    0.000    0.000 parallel.py:1356(_initialize_backend)\n",
            "        1    0.000    0.000    0.000    0.000 parallel.py:142(_get_active_backend)\n",
            "        1    0.000    0.000    0.000    0.000 parallel.py:1520(_get_batch_size)\n",
            "        3    0.000    0.000    0.000    0.000 parallel.py:1546(print_progress)\n",
            "        4    0.000    0.000    0.041    0.010 parallel.py:1819(_get_sequential_output)\n",
            "        1    0.000    0.000    0.000    0.000 parallel.py:1863(_reset_run_tracking)\n",
            "        1    0.000    0.000    0.041    0.041 parallel.py:1902(__call__)\n",
            "        2    0.000    0.000    0.000    0.000 parallel.py:24(_with_config)\n",
            "        1    0.000    0.000    0.041    0.041 parallel.py:54(__call__)\n",
            "        3    0.000    0.000    0.000    0.000 parallel.py:73(<genexpr>)\n",
            "        2    0.000    0.000    0.000    0.000 parallel.py:81(delayed)\n",
            "        2    0.000    0.000    0.000    0.000 pipeline.py:1045(_can_transform)\n",
            "        2    0.000    0.000    0.040    0.020 pipeline.py:1050(transform)\n",
            "      6/4    0.000    0.000    0.011    0.003 pipeline.py:1218(__sklearn_tags__)\n",
            "    17/14    0.000    0.000    0.002    0.000 pipeline.py:1233(<genexpr>)\n",
            "        3    0.000    0.000    0.000    0.000 pipeline.py:1296(__sklearn_is_fitted__)\n",
            "        2    0.000    0.000    0.041    0.020 pipeline.py:1509(_transform_one)\n",
            "        8    0.000    0.000    0.000    0.000 pipeline.py:358(_iter)\n",
            "        5    0.000    0.000    0.000    0.000 pipeline.py:426(_final_estimator)\n",
            "        6    0.000    0.000    0.011    0.002 pipeline.py:44(_raise_or_warn_if_not_fitted)\n",
            "        1    0.000    0.000    0.059    0.059 pipeline.py:738(predict)\n",
            "        1    0.000    0.000    0.000    0.000 pipeline.py:76(check)\n",
            "        1    0.000    0.000    0.000    0.000 process.py:198(daemon)\n",
            "        1    0.000    0.000    0.000    0.000 process.py:37(current_process)\n",
            "        1    0.000    0.000    0.000    0.000 queue.py:206(_init)\n",
            "        1    0.000    0.000    0.000    0.000 queue.py:34(__init__)\n",
            "       18    0.000    0.000    0.000    0.000 series.py:1480(_clear_item_cache)\n",
            "       18    0.000    0.000    0.003    0.000 series.py:389(__init__)\n",
            "        2    0.000    0.000    0.001    0.000 series.py:4789(apply)\n",
            "        2    0.000    0.000    0.000    0.000 series.py:6418(_reduce)\n",
            "        2    0.000    0.000    0.000    0.000 series.py:6459(any)\n",
            "        2    0.000    0.000    0.000    0.000 series.py:660(_constructor)\n",
            "        2    0.000    0.000    0.000    0.000 series.py:707(dtype)\n",
            "       18    0.000    0.000    0.000    0.000 series.py:734(name)\n",
            "       18    0.000    0.000    0.000    0.000 series.py:784(name)\n",
            "       34    0.000    0.000    0.000    0.000 series.py:831(_values)\n",
            "        4    0.000    0.000    0.000    0.000 series.py:914(__len__)\n",
            "        7    0.000    0.000    0.000    0.000 take.py:120(_take_nd_ndarray)\n",
            "        7    0.000    0.000    0.000    0.000 take.py:325(_get_take_nd_function)\n",
            "        7    0.000    0.000    0.000    0.000 take.py:564(_take_preprocess_indexer_and_fill_value)\n",
            "        7    0.000    0.000    0.000    0.000 take.py:59(take_nd)\n",
            "        1    0.000    0.000    0.000    0.000 threading.py:1453(current_thread)\n",
            "        3    0.000    0.000    0.000    0.000 threading.py:243(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 threading.py:90(RLock)\n",
            "       28    0.000    0.000    0.000    0.000 typing.py:2287(cast)\n",
            "        6    0.000    0.000    0.000    0.000 utils.py:62(is_list_like_indexer)\n",
            "        1    0.000    0.000    0.000    0.000 uuid.py:139(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 uuid.py:334(hex)\n",
            "        1    0.000    0.000    0.000    0.000 uuid.py:721(uuid4)\n",
            "        2    0.000    0.000    0.000    0.000 validation.py:1181(_check_large_sparse)\n",
            "        1    0.000    0.000    0.000    0.000 validation.py:130(_assert_all_finite_element_wise)\n",
            "     12/9    0.000    0.000    0.001    0.000 validation.py:1635(_is_fitted)\n",
            "        9    0.000    0.000    0.000    0.000 validation.py:1667(<listcomp>)\n",
            "     12/9    0.000    0.000    0.012    0.001 validation.py:1673(check_is_fitted)\n",
            "       62    0.000    0.000    0.000    0.000 validation.py:2343(_is_pandas_df)\n",
            "       43    0.000    0.000    0.000    0.000 validation.py:2352(_is_polars_df_or_series)\n",
            "        6    0.000    0.000    0.000    0.000 validation.py:2370(_get_feature_names)\n",
            "      163    0.000    0.000    0.000    0.000 validation.py:2413(<genexpr>)\n",
            "        5    0.000    0.000    0.000    0.000 validation.py:2687(_check_feature_names)\n",
            "        5    0.000    0.000    0.000    0.000 validation.py:2780(_check_n_features)\n",
            "        4    0.000    0.000    0.010    0.002 validation.py:2835(validate_data)\n",
            "        2    0.000    0.000    0.000    0.000 validation.py:305(_is_arraylike)\n",
            "        2    0.000    0.000    0.000    0.000 validation.py:313(_is_arraylike_not_scalar)\n",
            "       51    0.000    0.000    0.000    0.000 validation.py:318(_use_interchange_protocol)\n",
            "        5    0.000    0.000    0.000    0.000 validation.py:328(_num_features)\n",
            "       51    0.000    0.000    0.001    0.000 validation.py:381(_num_samples)\n",
            "        2    0.000    0.000    0.000    0.000 validation.py:536(_ensure_sparse_format)\n",
            "       50    0.000    0.000    0.000    0.000 validation.py:673(_ensure_no_complex_data)\n",
            "       50    0.000    0.000    0.000    0.000 validation.py:683(_check_estimator_name)\n",
            "       80    0.000    0.000    0.002    0.000 validation.py:692(_pandas_dtype_needs_early_conversion)\n",
            "       48    0.000    0.000    0.000    0.000 validation.py:731(_is_extension_array_dtype)\n",
            "       50    0.001    0.000    0.012    0.000 validation.py:736(check_array)\n",
            "        5    0.000    0.000    0.001    0.000 validation.py:90(_assert_all_finite)\n",
            "       80    0.000    0.000    0.000    0.000 validation.py:917(is_sparse)\n",
            "       82    0.000    0.000    0.002    0.000 validation.py:927(<genexpr>)\n",
            "       82    0.000    0.000    0.000    0.000 validation.py:930(<genexpr>)\n",
            "       64    0.000    0.000    0.000    0.000 warnings.py:166(simplefilter)\n",
            "       64    0.000    0.000    0.000    0.000 warnings.py:182(_add_filter)\n",
            "       70    0.000    0.000    0.000    0.000 warnings.py:441(__init__)\n",
            "       70    0.000    0.000    0.000    0.000 warnings.py:467(__enter__)\n",
            "       70    0.000    0.000    0.000    0.000 warnings.py:488(__exit__)\n",
            "      100    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x93d380}\n",
            "     1568    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}\n",
            "       86    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
            "       12    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
            "      204    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
            "        2    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
            "    53/49    0.000    0.000    0.010    0.000 {built-in method builtins.all}\n",
            "  549/463    0.008    0.000    0.016    0.000 {built-in method builtins.any}\n",
            "        4    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
            "        1    0.000    0.000    0.059    0.059 {built-in method builtins.exec}\n",
            "2301/2299    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
            "     1832    0.001    0.000    0.004    0.000 {built-in method builtins.hasattr}\n",
            "       68    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
            "      119    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
            "     5113    0.002    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
            "      197    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
            "  736/578    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
            "       15    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
            "       11    0.000    0.000    0.011    0.001 {built-in method builtins.next}\n",
            "        6    0.000    0.000    0.000    0.000 {built-in method builtins.repr}\n",
            "      228    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
            "        5    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
            "      981    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
            "       42    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
            "        2    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
            "       34    0.000    0.000    0.000    0.000 {built-in method math.isnan}\n",
            "        3    0.000    0.000    0.000    0.000 {built-in method numpy._core._multiarray_umath._make_extobj}\n",
            "       33    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
            "        6    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
            "  209/204    0.002    0.000    0.002    0.000 {built-in method numpy.asarray}\n",
            "       63    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
            "        7    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method posix.urandom}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method scipy.sparse._sparsetools.coo_tocsr}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method scipy.sparse._sparsetools.csr_has_canonical_format}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method scipy.sparse._sparsetools.csr_matvec}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method scipy.sparse._sparsetools.expandptr}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
            "       10    0.000    0.000    0.000    0.000 {function Bunch.__getitem__ at 0x79c6f9319b20}\n",
            "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
            "        6    0.000    0.000    0.000    0.000 {method '__reduce_ex__' of 'object' objects}\n",
            "      176    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
            "        4    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
            "      341    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'as_arrays' of 'numpy._core._multiarray_umath._array_converter' objects}\n",
            "       25    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
            "      302    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
            "        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
            "        4    0.000    0.000    0.000    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
            "      122    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
            "      170    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
            "       64    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
            "      108    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
            "       49    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
            "       13    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
            "       10    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
            "       42    0.000    0.000    0.000    0.000 {method 'mro' of 'type' objects}\n",
            "        4    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
            "       40    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
            "        9    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
            "       83    0.001    0.000    0.001    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
            "       64    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'repeat' of 'numpy.ndarray' objects}\n",
            "        3    0.000    0.000    0.000    0.000 {method 'reset' of '_contextvars.ContextVar' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
            "       17    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
            "        3    0.000    0.000    0.000    0.000 {method 'set' of '_contextvars.ContextVar' objects}\n",
            "       18    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
            "       39    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
            "       19    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
            "        4    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
            "       44    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
            "       42    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'wrap' of 'numpy._core._multiarray_umath._array_converter' objects}\n",
            "\n",
            "\n",
            "\n",
            " Uso máximo de memoria: 325.96 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Matriz de Confusión\n",
        "\n",
        "|                 | Predicho No Cara | Predicho Cara |\n",
        "|-----------------|------------------|---------------|\n",
        "| **Real No Cara**| 183              | 10            |\n",
        "| **Real Cara**   | 12               | 87            |\n",
        "\n",
        "### Métricas de Clasificación\n",
        "\n",
        "- **Accuracy general**: 0.92  \n",
        "- **F1-score macro promedio**: 0.92  \n",
        "- **F1-score ponderado**: 0.92\n",
        "\n",
        "| Clase | Precisión | Recall | F1-score | Soporte |\n",
        "|-------|-----------|--------|----------|---------|\n",
        "| No Cara (0) | 0.94 | 0.95 | 0.94 | 193 |\n",
        "| Cara     (1) | 0.90 | 0.88 | 0.89 |  99 |\n",
        "\n",
        "\n",
        "###  Análisis del Desempeño\n",
        "\n",
        "- El modelo acierta **183 de 193** viviendas no caras y **87 de 99** viviendas caras.\n",
        "- Hay **10 falsos positivos** (casas no caras clasificadas como caras) y **12 falsos negativos** (casas caras no detectadas).\n",
        "- Se **equivoca ligeramente más en la clase \"Cara\"**, lo cual es importante si el objetivo es identificar propiedades valiosas.\n",
        "\n",
        "###  Relevancia de los errores\n",
        "\n",
        "- **Falsos negativos (12)** podrían ser costosos si el modelo se usa para detectar oportunidades de inversión en propiedades de alto valor.\n",
        "- Sin embargo, los valores de F1-score indican que el modelo **mantiene un equilibrio excelente** entre precisión y sensibilidad para ambas clases.\n",
        "\n",
        "\n",
        "### ⚙️ Evaluación de eficiencia computacional\n",
        "\n",
        "#### ⏱ Tiempo de ejecución (`cProfile`)\n",
        "```text\n",
        "32,035 function calls (31,252 primitive calls) in 0.059 seconds\n"
      ],
      "metadata": {
        "id": "gf2wLpnhhaip"
      },
      "id": "gf2wLpnhhaip"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O1I25wZwq5-e"
      },
      "id": "O1I25wZwq5-e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Punto 9: Comparación de modelos y selección del mejor\n",
        "\n",
        "**Enunciado:**  \n",
        "Determine cual de todos los modelos es mejor, puede usar AIC y BIC para esto, además de los parámetros\n",
        "de la matriz de confusión y los del profiler.\n",
        "\n"
      ],
      "metadata": {
        "id": "un9ViLZVq-1m"
      },
      "id": "un9ViLZVq-1m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Durante esta entrega se aplicaron dos enfoques distintos para el modelo de regresión logística:\n",
        "\n",
        "1. **Regresión Logística con `scikit-learn`**, utilizando validación cruzada y ajuste de hiperparámetros con `GridSearchCV`.\n",
        "2. **Regresión Logística con `statsmodels`**, incluyendo análisis de significancia, cálculo de VIF, y criterios AIC y BIC.\n",
        "\n",
        "###  Comparación de desempeño\n",
        "\n",
        "| Criterio                  | `scikit-learn` (tuneado) | `statsmodels` |\n",
        "|---------------------------|--------------------------|----------------|\n",
        "| Accuracy en prueba        | 0.92                     | ~0.91          |\n",
        "| F1-score clase 1 (caras)  | 0.89                     | menor          |\n",
        "| Matriz de confusión       | 10 FP, 12 FN             | similar        |\n",
        "| AIC / BIC                 | ❌ No disponible          | ✅ AIC: 189.2 / BIC: 214.9 |\n",
        "| Velocidad (con `cProfile`)| ✅ Muy rápida             | ⚠️ Más lenta    |\n",
        "| Memoria (`memory_profiler`)| ✅ Baja                  | ✅ Baja         |\n",
        "| Interpretabilidad         | ⚠️ Menor                  | ✅ Alta (coef. y p-valores) |\n",
        "\n",
        "###  Análisis\n",
        "\n",
        "- El modelo de `scikit-learn` mostró mejor desempeño predictivo, especialmente en precisión y recall para clasificar viviendas **caras**.\n",
        "- El modelo de `statsmodels` ofreció una alta interpretabilidad, ideal para análisis explicativos, y permitió calcular AIC/BIC, que mostraron un modelo estadísticamente eficiente con **AIC = 189.2** y **BIC = 214.9**.\n",
        "- En términos de uso de recursos, ambos modelos fueron eficientes en memoria, aunque el modelo de `sklearn` es más rápido y escalable.\n",
        "\n",
        "###  Conclusión\n",
        "\n",
        "**El mejor modelo en esta entrega es el modelo de Regresión Logística con `scikit-learn` tunado**, ya que:\n",
        "- Presentó el mejor desempeño predictivo.\n",
        "- Tiene bajo costo computacional.\n",
        "- Generaliza bien en el conjunto de prueba.\n",
        "- Fue ajustado con penalización L2 y `C = 0.1`.\n",
        "\n",
        "El modelo de `statsmodels` queda como una herramienta de validación estadística y apoyo interpretativo.\n"
      ],
      "metadata": {
        "id": "vhyFYq03qzx0"
      },
      "id": "vhyFYq03qzx0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Punto 10: Modelo de regresión logística para la variable categórica para el precio de las casas\n",
        "\n",
        "**Enunciado:**  \n",
        "Haga un modelo de regresión logística para la variable categórica para el precio de las casas (categorías:\n",
        "barata, media y cara). Asegúrese de tunearlo para obtener el mejor modelo posible.\n"
      ],
      "metadata": {
        "id": "nSRSzzg3rfHX"
      },
      "id": "nSRSzzg3rfHX"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Cargar datos ---\n",
        "df = pd.read_csv(\"data/train_cat.csv\")\n",
        "X = df.drop(columns=['SalePrice', 'is_barata', 'is_media', 'is_cara', 'cat_price'])\n",
        "y = df['cat_price']  # variable multiclase\n",
        "\n",
        "# --- Separar datos ---\n",
        "SEED = 221087\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
        "\n",
        "# --- Preprocesamiento ---\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = X.select_dtypes(exclude=['int64', 'float64']).columns\n",
        "\n",
        "num_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "prepro = ColumnTransformer([\n",
        "    ('num', num_pipe, num_cols),\n",
        "    ('cat', cat_pipe, cat_cols)\n",
        "])\n",
        "\n",
        "# --- Pipeline del modelo ---\n",
        "pipe = Pipeline([\n",
        "    ('prep', prepro),\n",
        "    ('clf', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=1000, random_state=SEED))\n",
        "])\n",
        "\n",
        "# --- GridSearchCV para tunear ---\n",
        "param_grid = {\n",
        "    'clf__penalty': ['l2', 'elasticnet'],\n",
        "    'clf__C': [0.01, 0.1, 1],\n",
        "    'clf__l1_ratio': [0.0, 0.5, 1.0]  # solo para elasticnet\n",
        "}\n",
        "\n",
        "# Validar penalización compatible\n",
        "grid = GridSearchCV(pipe, param_grid=[\n",
        "    {\n",
        "        'clf__penalty': ['l2'],\n",
        "        'clf__C': [0.01, 0.1, 1]\n",
        "    },\n",
        "    {\n",
        "        'clf__penalty': ['elasticnet'],\n",
        "        'clf__C': [0.01, 0.1, 1],\n",
        "        'clf__l1_ratio': [0.0, 0.5, 1.0]\n",
        "    }\n",
        "], cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
        "\n",
        "# --- Entrenar modelo ---\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluación ---\n",
        "y_pred = grid.predict(X_test)\n",
        "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
        "print(\"\\nReporte de clasificación:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# --- Matriz de Confusión ---\n",
        "cm = confusion_matrix(y_test, y_pred, labels=['barata', 'media', 'cara'])\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=['barata', 'media', 'cara'],\n",
        "            yticklabels=['barata', 'media', 'cara'])\n",
        "plt.title(\"Matriz de Confusión - Regresión Logística Multiclase\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "aiD8mOb0rqEN",
        "outputId": "5edc45b0-1cbf-4d5c-c905-1b7d8f7ff355"
      },
      "id": "aiD8mOb0rqEN",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados: {'clf__C': 1, 'clf__l1_ratio': 0.5, 'clf__penalty': 'elasticnet'}\n",
            "\n",
            "Reporte de clasificación:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      barata       0.91      0.89      0.90        97\n",
            "        cara       0.86      0.90      0.88        99\n",
            "       media       0.78      0.77      0.77        96\n",
            "\n",
            "    accuracy                           0.85       292\n",
            "   macro avg       0.85      0.85      0.85       292\n",
            "weighted avg       0.85      0.85      0.85       292\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " modelo clasificó correctamente la mayoría de las viviendas baratas y caras, con F1-scores de 0.90 y 0.88, respectivamente.\n",
        "\n",
        "La categoría media fue la más difícil de predecir, con un F1-score más bajo (0.77), y con más confusiones tanto con “barata” como con “cara”.\n",
        "\n",
        "La matriz de confusión muestra que:\n",
        "\n",
        "- 11 viviendas baratas fueron clasificadas incorrectamente como medias.\n",
        "\n",
        "- 14 viviendas medias fueron clasificadas como caras.\n",
        "\n",
        "- 10 viviendas caras fueron clasificadas como medias.\n",
        "\n",
        "El modelo multiclase ajustado con regresión logística muestra un rendimiento sólido, especialmente en los extremos del precio (barata, cara). La clase intermedia (media) presenta mayor ambigüedad, posiblemente por compartir características con ambas clases adyacentes.\n",
        "\n",
        "Este modelo sirve como base robusta para evaluar frente a otros clasificadores multiclase como Árboles de Decisión o Random Forest, y se puede mejorar aún más con ingeniería de características o reagrupación de clases si fuese necesario.\n",
        "\n"
      ],
      "metadata": {
        "id": "h4Uw6ut9sssf"
      },
      "id": "h4Uw6ut9sssf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Punto 11: Comparación de modelos de clasificación\n",
        "\n",
        "**Enunciado:**  \n",
        "Compare la eficiencia del modelo anterior con los de clasificación de las entregas anteriores ¿Cuál se\n",
        "demoró más en procesar?¿Cuál se equivocó más?¿Cuál se equivocó menos?¿por qué?\n",
        "\n",
        "\n",
        "Se compararon los siguientes modelos de clasificación desarrollados a lo largo del proyecto para predecir la categoría de precio de una vivienda (`barata`, `media`, `cara`):\n",
        "\n",
        "###  Modelos evaluados:\n",
        "\n",
        "- **Regresión Logística** (Entrega 5)\n",
        "- **K-Nearest Neighbors (KNN)** (Entrega 2)\n",
        "- **Naive Bayes** (Parte 3)\n",
        "- **Random Forest** (Parte 3)\n",
        "\n",
        "\n",
        "\n",
        "###  Resultados comparativos\n",
        "\n",
        "| Modelo             | Accuracy | F1 Macro | Procesamiento | Observaciones |\n",
        "|--------------------|----------|----------|---------------|----------------|\n",
        "| **Regresión Logística** | 0.85     | 0.85     | Medio         | Fuerte en extremos (barata/cara), débil en media |\n",
        "| **KNN**                | ~0.81    | ~0.80    | Lento (conjunto grande) | Sensible a la escala y datos similares |\n",
        "| **Naive Bayes**        | ~0.74    | Bajo     | Muy rápido     | Alto error por suposiciones fuertes |\n",
        "| **Random Forest**      | **0.88** | **~0.88**| Más lento (entrenamiento) | Mejor equilibrio general en todas las clases |\n",
        "\n",
        "\n",
        "\n",
        "### ⏱️ ¿Cuál se demoró más?\n",
        "\n",
        "-  **Random Forest** fue el **más lento al entrenar**, debido a que construye múltiples árboles de decisión.\n",
        "-  **KNN** fue lento al predecir, ya que calcula distancias con todos los datos.\n",
        "-  **Naive Bayes** fue el **más rápido** tanto en entrenamiento como en predicción.\n",
        "\n",
        "\n",
        "\n",
        "###  ¿Cuál se equivocó más?\n",
        "\n",
        "- **Naive Bayes** tuvo el **mayor número de errores**, especialmente en confundir viviendas \"medias\" con otras clases, debido a suponer independencia entre características.\n",
        "\n",
        "\n",
        "\n",
        "###  ¿Cuál se equivocó menos?\n",
        "\n",
        "- **Random Forest** fue el modelo con **menos errores**, tanto en clasificación global como en clases individuales, gracias a su capacidad para capturar relaciones no lineales y manejar bien atributos categóricos y numéricos.\n",
        "\n",
        "\n",
        "\n",
        "###  ¿Por qué?\n",
        "\n",
        "- **Naive Bayes** falla más porque **supone independencia entre variables**, lo cual no se cumple en datos inmobiliarios (por ejemplo, superficie y número de habitaciones están correlacionados).\n",
        "- **KNN** depende mucho de la escala y no generaliza bien con muchos atributos o ruido.\n",
        "- **Regresión Logística** logra buen balance, pero puede no capturar relaciones no lineales.\n",
        "- **Random Forest** combina múltiples árboles para **reducir sobreajuste y capturar complejidad**, por lo tanto es más preciso.\n",
        "\n",
        "\n",
        "\n",
        "###  Conclusión final\n",
        "\n",
        "El mejor modelo es **Random Forest**, ya que:\n",
        "- Obtuvo la mayor precisión (≈ 88%)\n",
        "- Manejó bien las tres clases\n",
        "- Presentó menor cantidad de errores\n",
        "- A pesar de ser más costoso computacionalmente, ofrece el mejor rendimiento general para tareas de clasificación multiclase en este proyecto.\n"
      ],
      "metadata": {
        "id": "d-9dzbU_tURZ"
      },
      "id": "d-9dzbU_tURZ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}